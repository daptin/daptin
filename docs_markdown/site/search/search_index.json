{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Link Daptin is a headless CMS server which servers data from MySQL/PostgreSQL/SQLite over JSONAPI.org or GraphQL. With Daptin you can design your data model and have a production ready APIs reliably backed by persistent database online with in hours. Features Link Consume the following features easily on any device Database backed persistence, 3NF normalized tables JSON API / GraphQL for CRUD apis User and group management and access control Social login with OAuth : tested with google, github, linkedin Actions for abstracting out business flows Extensive state tracking APIs Enable Data Auditing from a single toggle Synchronous Data Exchange with 3rd party APIs Multilingual tables support, supports Accept-Language header Cloud storage sync like gdrive, dropbox, b2, s3 and more Asset column to hold file and blob data, backed by storage Multiple websites under separate sub-domain/sub-paths Connect with external APIs by using extension points Data View Streams Flexible data import (auto create new tables and automated schema generation) XLSX JSON CSV Database to have consistent single source of truth [Postgres/MySQL/SQLite] Flexible auth using the JWT-based authentication & permission system Works with all frontend frameworks like React, Vue.js, Angular, Android, iOS Very low memory requirement and horizontally scalable Can be deployed on a wide range of hardware arm5,arm6,arm7,arm64,mips,mips64,mips64le,mipsle (or build for your target using go) Guides Link Create a site using a google drive folder Creating a todo list backend","title":"Introduction"},{"location":"#introduction","text":"Daptin is a headless CMS server which servers data from MySQL/PostgreSQL/SQLite over JSONAPI.org or GraphQL. With Daptin you can design your data model and have a production ready APIs reliably backed by persistent database online with in hours.","title":"Introduction"},{"location":"#features","text":"Consume the following features easily on any device Database backed persistence, 3NF normalized tables JSON API / GraphQL for CRUD apis User and group management and access control Social login with OAuth : tested with google, github, linkedin Actions for abstracting out business flows Extensive state tracking APIs Enable Data Auditing from a single toggle Synchronous Data Exchange with 3rd party APIs Multilingual tables support, supports Accept-Language header Cloud storage sync like gdrive, dropbox, b2, s3 and more Asset column to hold file and blob data, backed by storage Multiple websites under separate sub-domain/sub-paths Connect with external APIs by using extension points Data View Streams Flexible data import (auto create new tables and automated schema generation) XLSX JSON CSV Database to have consistent single source of truth [Postgres/MySQL/SQLite] Flexible auth using the JWT-based authentication & permission system Works with all frontend frameworks like React, Vue.js, Angular, Android, iOS Very low memory requirement and horizontally scalable Can be deployed on a wide range of hardware arm5,arm6,arm7,arm64,mips,mips64,mips64le,mipsle (or build for your target using go)","title":"Features"},{"location":"#guides","text":"Create a site using a google drive folder Creating a todo list backend","title":"Guides"},{"location":"actions/actions/","text":"What are actions Link Actions are the most useful concept in Daptin and we will see that everything you have done in Daptin was an action api call. Actions can be thought of as follows: A set of inputs (key value pair) A set of outcomes based on the inputs What are actions and why do I need this Link Create/Read/Update/Delete (CRUD) APIs are only basic APIs exposed on the database, and you would rarely want to make those API available to your end user. Reasons could be multiple The end user doesn't (immediately) owe the data they create Creating a \"row\"/\"data entry\" entry doesn't signify completion of a process or a flow Usually a \"set of entities\" is to be created and not just a single entity (when you create a user, you also want to create a usergroup also and associate the user to usergroup) You could allow user to update only some fields of an entity and not all fields (eg user can change their name, but not email) Changes based on some entity (when you are going though a project, a new item should automatically belong to that project) Actions provide a powerful abstraction over the CRUD and handle all of these use cases. To quickly understand what actions are, lets see what happened when you \"signed up\" on Daptin. Take a look at how \"Sign up\" action is defined in Daptin. We will go through each part of this definition An action is performed on an entity. Let's also remember that world is an entity itself. Action schema Link { Name: \"signup\", Label: \"Sign up\", InstanceOptional: true, OnType: \"user_account\", InFields: []api2go.ColumnInfo{ { Name: \"name\", ColumnName: \"name\", ColumnType: \"label\", IsNullable: false, }, { Name: \"email\", ColumnName: \"email\", ColumnType: \"email\", IsNullable: false, }, { Name: \"password\", ColumnName: \"password\", ColumnType: \"password\", IsNullable: false, }, { Name: \"Password Confirm\", ColumnName: \"passwordConfirm\", ColumnType: \"password\", IsNullable: false, }, }, Validations: []ColumnTag{ { ColumnName: \"email\", Tags: \"email\", }, { ColumnName: \"name\", Tags: \"required\", }, { ColumnName: \"password\", Tags: \"eqfield=InnerStructField[passwordConfirm],min=8\", }, }, Conformations: []ColumnTag{ { ColumnName: \"email\", Tags: \"email\", }, { ColumnName: \"name\", Tags: \"trim\", }, }, OutFields: { { Type: \"user_account\", Method: \"POST\", Reference: \"user\", Attributes: { \"name\": \"~name\", \"email\": \"~email\", \"password\": \"~password\", \"confirmed\": \"0\", }, }, { Type: \"usergroup\", Method: \"POST\", Reference: \"usergroup\", Attributes: { \"name\": \"!'Home group for ' + user.name\", }, }, { Type: \"user_user_id_has_usergroup_usergroup_id\", Method: \"POST\", Reference: \"user_usergroup\", Attributes: { \"user_id\": \"$user.reference_id\", \"usergroup_id\": \"$usergroup.reference_id\", }, }, { Type: \"client.notify\", Method: \"ACTIONRESPONSE\", Attributes: { \"type\": \"success\", \"title\": \"Success\", \"message\": \"Signup Successful\", }, }, { Type: \"client.redirect\", Method: \"ACTIONRESPONSE\", Attributes: { \"location\": \"/auth/signin\", \"window\": \"self\", }, }, }, } Action Name Link Name: \"signup\", Name of the action, this should be unique for each actions. Actions are identified by this name Action Label Link Label: \"Sign up\", Label is for humans OnType Link OnType: \"user_account\", The primary type of entity on which the action happens. This is used to know where the actions should come up on the UI Action instance Link InstanceOptional: true, If the action requires an \"instance\" of that type on which the action is defined (more about this below). So \"Sign up\" is defined on \"user\" table, but an instance of \"user\" is not required to initiate the action. This is why the \"Sign up\" doesnt ask you to select a user (which wouldn't make sense either) Input fields Link InFields: []api2go.ColumnInfo This is a set of inputs which the user need to fill in to initiate that action. As we see here in case of \"Sign up\", we ask for four inputs Name Email Password Confirm password Note that the ColumnInfo structure is the same one we used to define tables . Validations Link Validations: []ColumnTag Validations validate the user input and rejects if some validation fails { ColumnName: \"email\", Tags: \"email\", }, This tells that the \"email\" input should actually be an email. One of the more interesting validations is cross field check { ColumnName: \"password\", Tags: \"eqfield=InnerStructField[passwordConfirm],min=8\", }, This tells that the value entered by user in the password field should be equal to the value in passwordConfirm field. And the minimum length should be 8 characters. Conformations Link Conformations: []ColumnTag Conformations help to clean the data before the action is carried out. The frequently one used are trim and email . Trim: trim removes white spaces, which are sometimes accidently introduced when entering data Email: email conformation will normalize the email. Things like lowercase + trim OutFields Link OutFields: []Outcome OutFields are the list of outcomes which the action will result in. The outcomes are evaluated in a top to bottom manner, and the result of one outcome is accessible when evaluating the next outcome. We have defined three outcomes in our \"Sign Up\" action. Create a user { Type: \"user_account\", Method: \"POST\", Reference: \"user\", Attributes: map[string]interface{}{ \"name\": \"~name\", \"email\": \"~email\", \"password\": \"~password\", \"confirmed\": \"0\", }, }, This tells us that, the first outcome is of type \"user\". The outcome is a \"New User\" (POST). It could alternatively have been a Update/Find/Delete operation. The attributes maps the input fields to the fields of our new user. ~name will be the value entered by user in the name field ~email will be the entered in the email field, and so on If we skip the ~ , like \"confirmed\": \"0\" Then the literal value is used. Reference: \"user\", We have this to allow the \"outcome\" to be referenced when evaluating the next outcome. Let us see the other outcomes Scripted fields - \"!...\" Link { Type: \"usergroup\", Method: \"POST\", Reference: \"usergroup\", Attributes: map[string]interface{}{ \"name\": \"!'Home group for ' + user.name\", }, }, Daptin includes the otto js engine . An exclamation mark tell daptin to evaluate the rest of the string as Javascript. 'Home group for ' + user.name becomes \"Home group for parth\" Referencing previous outcomes Link { Type: \"user_user_id_has_usergroup_usergroup_id\", Method: \"POST\", Reference: \"user_usergroup\", Attributes: map[string]interface{}{ \"user_id\": \"$user.reference_id\", \"usergroup_id\": \"$usergroup.reference_id\", }, }, the $ sign is to refer the previous outcomes. Here this outcome adds the newly created user to the newly created usergroup.","title":"What are actions"},{"location":"actions/actions/#what-are-actions","text":"Actions are the most useful concept in Daptin and we will see that everything you have done in Daptin was an action api call. Actions can be thought of as follows: A set of inputs (key value pair) A set of outcomes based on the inputs","title":"What are actions"},{"location":"actions/actions/#what-are-actions-and-why-do-i-need-this","text":"Create/Read/Update/Delete (CRUD) APIs are only basic APIs exposed on the database, and you would rarely want to make those API available to your end user. Reasons could be multiple The end user doesn't (immediately) owe the data they create Creating a \"row\"/\"data entry\" entry doesn't signify completion of a process or a flow Usually a \"set of entities\" is to be created and not just a single entity (when you create a user, you also want to create a usergroup also and associate the user to usergroup) You could allow user to update only some fields of an entity and not all fields (eg user can change their name, but not email) Changes based on some entity (when you are going though a project, a new item should automatically belong to that project) Actions provide a powerful abstraction over the CRUD and handle all of these use cases. To quickly understand what actions are, lets see what happened when you \"signed up\" on Daptin. Take a look at how \"Sign up\" action is defined in Daptin. We will go through each part of this definition An action is performed on an entity. Let's also remember that world is an entity itself.","title":"What are actions and why do I need this"},{"location":"actions/actions/#action-schema","text":"{ Name: \"signup\", Label: \"Sign up\", InstanceOptional: true, OnType: \"user_account\", InFields: []api2go.ColumnInfo{ { Name: \"name\", ColumnName: \"name\", ColumnType: \"label\", IsNullable: false, }, { Name: \"email\", ColumnName: \"email\", ColumnType: \"email\", IsNullable: false, }, { Name: \"password\", ColumnName: \"password\", ColumnType: \"password\", IsNullable: false, }, { Name: \"Password Confirm\", ColumnName: \"passwordConfirm\", ColumnType: \"password\", IsNullable: false, }, }, Validations: []ColumnTag{ { ColumnName: \"email\", Tags: \"email\", }, { ColumnName: \"name\", Tags: \"required\", }, { ColumnName: \"password\", Tags: \"eqfield=InnerStructField[passwordConfirm],min=8\", }, }, Conformations: []ColumnTag{ { ColumnName: \"email\", Tags: \"email\", }, { ColumnName: \"name\", Tags: \"trim\", }, }, OutFields: { { Type: \"user_account\", Method: \"POST\", Reference: \"user\", Attributes: { \"name\": \"~name\", \"email\": \"~email\", \"password\": \"~password\", \"confirmed\": \"0\", }, }, { Type: \"usergroup\", Method: \"POST\", Reference: \"usergroup\", Attributes: { \"name\": \"!'Home group for ' + user.name\", }, }, { Type: \"user_user_id_has_usergroup_usergroup_id\", Method: \"POST\", Reference: \"user_usergroup\", Attributes: { \"user_id\": \"$user.reference_id\", \"usergroup_id\": \"$usergroup.reference_id\", }, }, { Type: \"client.notify\", Method: \"ACTIONRESPONSE\", Attributes: { \"type\": \"success\", \"title\": \"Success\", \"message\": \"Signup Successful\", }, }, { Type: \"client.redirect\", Method: \"ACTIONRESPONSE\", Attributes: { \"location\": \"/auth/signin\", \"window\": \"self\", }, }, }, }","title":"Action schema"},{"location":"actions/actions/#action-name","text":"Name: \"signup\", Name of the action, this should be unique for each actions. Actions are identified by this name","title":"Action Name"},{"location":"actions/actions/#action-label","text":"Label: \"Sign up\", Label is for humans","title":"Action Label"},{"location":"actions/actions/#ontype","text":"OnType: \"user_account\", The primary type of entity on which the action happens. This is used to know where the actions should come up on the UI","title":"OnType"},{"location":"actions/actions/#action-instance","text":"InstanceOptional: true, If the action requires an \"instance\" of that type on which the action is defined (more about this below). So \"Sign up\" is defined on \"user\" table, but an instance of \"user\" is not required to initiate the action. This is why the \"Sign up\" doesnt ask you to select a user (which wouldn't make sense either)","title":"Action instance"},{"location":"actions/actions/#input-fields","text":"InFields: []api2go.ColumnInfo This is a set of inputs which the user need to fill in to initiate that action. As we see here in case of \"Sign up\", we ask for four inputs Name Email Password Confirm password Note that the ColumnInfo structure is the same one we used to define tables .","title":"Input fields"},{"location":"actions/actions/#validations","text":"Validations: []ColumnTag Validations validate the user input and rejects if some validation fails { ColumnName: \"email\", Tags: \"email\", }, This tells that the \"email\" input should actually be an email. One of the more interesting validations is cross field check { ColumnName: \"password\", Tags: \"eqfield=InnerStructField[passwordConfirm],min=8\", }, This tells that the value entered by user in the password field should be equal to the value in passwordConfirm field. And the minimum length should be 8 characters.","title":"Validations"},{"location":"actions/actions/#conformations","text":"Conformations: []ColumnTag Conformations help to clean the data before the action is carried out. The frequently one used are trim and email . Trim: trim removes white spaces, which are sometimes accidently introduced when entering data Email: email conformation will normalize the email. Things like lowercase + trim","title":"Conformations"},{"location":"actions/actions/#outfields","text":"OutFields: []Outcome OutFields are the list of outcomes which the action will result in. The outcomes are evaluated in a top to bottom manner, and the result of one outcome is accessible when evaluating the next outcome. We have defined three outcomes in our \"Sign Up\" action. Create a user { Type: \"user_account\", Method: \"POST\", Reference: \"user\", Attributes: map[string]interface{}{ \"name\": \"~name\", \"email\": \"~email\", \"password\": \"~password\", \"confirmed\": \"0\", }, }, This tells us that, the first outcome is of type \"user\". The outcome is a \"New User\" (POST). It could alternatively have been a Update/Find/Delete operation. The attributes maps the input fields to the fields of our new user. ~name will be the value entered by user in the name field ~email will be the entered in the email field, and so on If we skip the ~ , like \"confirmed\": \"0\" Then the literal value is used. Reference: \"user\", We have this to allow the \"outcome\" to be referenced when evaluating the next outcome. Let us see the other outcomes","title":"OutFields"},{"location":"actions/actions/#scripted-fields-","text":"{ Type: \"usergroup\", Method: \"POST\", Reference: \"usergroup\", Attributes: map[string]interface{}{ \"name\": \"!'Home group for ' + user.name\", }, }, Daptin includes the otto js engine . An exclamation mark tell daptin to evaluate the rest of the string as Javascript. 'Home group for ' + user.name becomes \"Home group for parth\"","title":"Scripted fields - \"!...\""},{"location":"actions/actions/#referencing-previous-outcomes","text":"{ Type: \"user_user_id_has_usergroup_usergroup_id\", Method: \"POST\", Reference: \"user_usergroup\", Attributes: map[string]interface{}{ \"user_id\": \"$user.reference_id\", \"usergroup_id\": \"$usergroup.reference_id\", }, }, the $ sign is to refer the previous outcomes. Here this outcome adds the newly created user to the newly created usergroup.","title":"Referencing previous outcomes"},{"location":"actions/default_actions/","text":"Actions list Link Use actions to build work flows to carry out tasks like syncing data or emailing your users. You can also give access to these workflows to your users and restrict their access by altering their permission . The following actions are available by default on a fresh instance. These actions cannot be deleted and will be recreated if deleted directly from the database. Restart daptin Link Restarts daptin immediately and reads file system for new config and data files and apply updates to the APIs as necessary. Takes about 15 seconds (async) to reconfigure everything. var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFydHBhcjFAZ21haWwuY29tIiwiZXhwIjoxNTIzMTgzMTA0LCJpYXQiOiIyMDE4LTA0LTA1VDE1OjU1OjA0LjYyMzU4NTYxKzA1OjMwIiwiaXNzIjoiZGFwdGluIiwianRpIjoiNmJhMmFhZjgtODBlNS00OGIwLTgwZmItMzEzYzk3Nzg0Y2E4IiwibmFtZSI6InBhcnRoIiwibmJmIjoxNTIyOTIzOTA0LCJwaWN0dXJlIjoiaHR0cHM6Ly93d3cuZ3JhdmF0YXIuY29tL2F2YXRhci9mNGJmNmI2Nzg5NGU5MzAzYjZlMTczMTMyZWE0ZTkwYVx1MDAyNmQ9bW9uc3RlcmlkIn0.eb5Vp00cHLeshZBtwJIyarJ6RQOLeVPj15n8ubVnGYo' }; var dataString = '{\"attributes\":{}}' ; var options = { url : 'http://localhost:6336/action/world/restart_daptin' , method : 'POST' , headers : headers , body : dataString }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); Generate random data Link Generate random data of any entity type to play around. Takes in a count parameter and generates that many rows. Daptin uses a fake data generator to generate quality random data for a wide variety of fields. var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFydHBhcjFAZ21haWwuY29tIiwiZXhwIjoxNTIzMTgzMTA0LCJpYXQiOiIyMDE4LTA0LTA1VDE1OjU1OjA0LjYyMzU4NTYxKzA1OjMwIiwiaXNzIjoiZGFwdGluIiwianRpIjoiNmJhMmFhZjgtODBlNS00OGIwLTgwZmItMzEzYzk3Nzg0Y2E4IiwibmFtZSI6InBhcnRoIiwibmJmIjoxNTIyOTIzOTA0LCJwaWN0dXJlIjoiaHR0cHM6Ly93d3cuZ3JhdmF0YXIuY29tL2F2YXRhci9mNGJmNmI2Nzg5NGU5MzAzYjZlMTczMTMyZWE0ZTkwYVx1MDAyNmQ9bW9uc3RlcmlkIn0.eb5Vp00cHLeshZBtwJIyarJ6RQOLeVPj15n8ubVnGYo' , }; var dataString = '{\"attributes\":{\"count\":100,\"world_id\":\"a82bcd84-db3a-4542-b0ef-80e81fc62f8e\"}}' ; var options = { url : 'http://localhost:6336/action/world/generate_random_data' , method : 'POST' , headers : headers , body : dataString }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); Export data Link Export data as JSON dump. This will export for a single table if table_name param is specific, else it will export all data. Import data Link Import data from dump exported by Daptin. Takes in the following parameters: dump_file - json|yaml|toml|hcl truncate_before_insert: default false , specify true to tuncate tables before importing Upload file to a cloud store Link Upload file to external store cloud_store , may require oauth token and connection . file: any Upload XLS Link Upload xls to entity, takes in the following parameters: data_xls_file: xls, xlsx entity_name: existing table name or new to create a new entity create_if_not_exists: set true if creating a new entity (to avoid typo errors in above) add_missing_columns: set true if the file has extra columns which you want to be created Upload CSV Link Upload CSV to entity data_xls_file: xls, xlsx entity_name: existing table name or new to create a new entity create_if_not_exists: set true if creating a new entity (to avoid typo errors in above) add_missing_columns: set true if the file has extra columns which you want to be created Curl curl 'http://localhost:6336/action/world/upload_csv_to_system_schema' \\ -H 'Authorization: Bearer <Token>' \\ --data-binary '{ \"attributes\": { \"create_if_not_exists\": true, \"add_missing_columns\": true, \"data_csv_file\": [ { \"name\" : \"<file name>.csv\" , \"file\" : \"data:text/csv;base64,<File contents base64 here>\" , \"type\" : \"text/csv\" } ] , \"entity_name\": \"<entity name>\" } }' NodeJS Example import requests headers = { 'Authorization' : 'Bearer <Token>' , } data = '{ \"attributes\" : { \"create_if_not_exists\" : true , \"add_missing_columns\" : true , \"data_csv_file\" : [{ \"name\" : \"<file name>.csv\" , \"file\" : \"data:text/csv;base64,<File contents base64 here>\" , \"type\" : \"text/csv\" }], \"entity_name\" : \"<entity name>\" } } ' response = requests . post ( 'http://localhost:6336/action/world/upload_csv_to_system_schema' , headers = headers , data = data ) Upload schema Link Upload entity types or actions or any other config to daptin schema_file: json|yaml|toml|hcl restart, system_json_schema_update Download Schema Link Download a JSON config of the current daptin instance. This can be imported at a later stage to recreate a similar instance. Note, this contains only the structure and not the actual data. You can take a data dump separately. Or of a particular entity type Become administrator Link Become an admin user of the instance. Only the first user can do this, as long as there is no second user. Sign up Link Sign up a new user, takes in the following parameters name email password passwordConfirm Creates these rows : a new user a new usergroup for the user user belongs to the usergroup Sign in Link Sign in essentially generates a [JWT token] issued by Daptin which can be used in requests to authenticate as a user. email password Oauth login Link Authenticate via OAuth, this will redirect you to the oauth sign in page of the oauth connection. The response will be handeled by oauth login response Oauth login response Link This action is supposed to handle the oauth login response flow and not supposed to be invoked manually. Takes in the following parameters (standard oauth2 params) - code - state - authenticator Creates : oauth profile exchange: generate a token from oauth provider stores the oauth token + refresh token for later user Add data exchange Link Add new data sync with google-sheets name sheet_id app_key Creates a data exchange","title":"Actions list"},{"location":"actions/default_actions/#actions-list","text":"Use actions to build work flows to carry out tasks like syncing data or emailing your users. You can also give access to these workflows to your users and restrict their access by altering their permission . The following actions are available by default on a fresh instance. These actions cannot be deleted and will be recreated if deleted directly from the database.","title":"Actions list"},{"location":"actions/default_actions/#restart-daptin","text":"Restarts daptin immediately and reads file system for new config and data files and apply updates to the APIs as necessary. Takes about 15 seconds (async) to reconfigure everything. var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFydHBhcjFAZ21haWwuY29tIiwiZXhwIjoxNTIzMTgzMTA0LCJpYXQiOiIyMDE4LTA0LTA1VDE1OjU1OjA0LjYyMzU4NTYxKzA1OjMwIiwiaXNzIjoiZGFwdGluIiwianRpIjoiNmJhMmFhZjgtODBlNS00OGIwLTgwZmItMzEzYzk3Nzg0Y2E4IiwibmFtZSI6InBhcnRoIiwibmJmIjoxNTIyOTIzOTA0LCJwaWN0dXJlIjoiaHR0cHM6Ly93d3cuZ3JhdmF0YXIuY29tL2F2YXRhci9mNGJmNmI2Nzg5NGU5MzAzYjZlMTczMTMyZWE0ZTkwYVx1MDAyNmQ9bW9uc3RlcmlkIn0.eb5Vp00cHLeshZBtwJIyarJ6RQOLeVPj15n8ubVnGYo' }; var dataString = '{\"attributes\":{}}' ; var options = { url : 'http://localhost:6336/action/world/restart_daptin' , method : 'POST' , headers : headers , body : dataString }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback );","title":"Restart daptin"},{"location":"actions/default_actions/#generate-random-data","text":"Generate random data of any entity type to play around. Takes in a count parameter and generates that many rows. Daptin uses a fake data generator to generate quality random data for a wide variety of fields. var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFydHBhcjFAZ21haWwuY29tIiwiZXhwIjoxNTIzMTgzMTA0LCJpYXQiOiIyMDE4LTA0LTA1VDE1OjU1OjA0LjYyMzU4NTYxKzA1OjMwIiwiaXNzIjoiZGFwdGluIiwianRpIjoiNmJhMmFhZjgtODBlNS00OGIwLTgwZmItMzEzYzk3Nzg0Y2E4IiwibmFtZSI6InBhcnRoIiwibmJmIjoxNTIyOTIzOTA0LCJwaWN0dXJlIjoiaHR0cHM6Ly93d3cuZ3JhdmF0YXIuY29tL2F2YXRhci9mNGJmNmI2Nzg5NGU5MzAzYjZlMTczMTMyZWE0ZTkwYVx1MDAyNmQ9bW9uc3RlcmlkIn0.eb5Vp00cHLeshZBtwJIyarJ6RQOLeVPj15n8ubVnGYo' , }; var dataString = '{\"attributes\":{\"count\":100,\"world_id\":\"a82bcd84-db3a-4542-b0ef-80e81fc62f8e\"}}' ; var options = { url : 'http://localhost:6336/action/world/generate_random_data' , method : 'POST' , headers : headers , body : dataString }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback );","title":"Generate random data"},{"location":"actions/default_actions/#export-data","text":"Export data as JSON dump. This will export for a single table if table_name param is specific, else it will export all data.","title":"Export data"},{"location":"actions/default_actions/#import-data","text":"Import data from dump exported by Daptin. Takes in the following parameters: dump_file - json|yaml|toml|hcl truncate_before_insert: default false , specify true to tuncate tables before importing","title":"Import data"},{"location":"actions/default_actions/#upload-file-to-a-cloud-store","text":"Upload file to external store cloud_store , may require oauth token and connection . file: any","title":"Upload file to a cloud store"},{"location":"actions/default_actions/#upload-xls","text":"Upload xls to entity, takes in the following parameters: data_xls_file: xls, xlsx entity_name: existing table name or new to create a new entity create_if_not_exists: set true if creating a new entity (to avoid typo errors in above) add_missing_columns: set true if the file has extra columns which you want to be created","title":"Upload XLS"},{"location":"actions/default_actions/#upload-csv","text":"Upload CSV to entity data_xls_file: xls, xlsx entity_name: existing table name or new to create a new entity create_if_not_exists: set true if creating a new entity (to avoid typo errors in above) add_missing_columns: set true if the file has extra columns which you want to be created Curl curl 'http://localhost:6336/action/world/upload_csv_to_system_schema' \\ -H 'Authorization: Bearer <Token>' \\ --data-binary '{ \"attributes\": { \"create_if_not_exists\": true, \"add_missing_columns\": true, \"data_csv_file\": [ { \"name\" : \"<file name>.csv\" , \"file\" : \"data:text/csv;base64,<File contents base64 here>\" , \"type\" : \"text/csv\" } ] , \"entity_name\": \"<entity name>\" } }' NodeJS Example import requests headers = { 'Authorization' : 'Bearer <Token>' , } data = '{ \"attributes\" : { \"create_if_not_exists\" : true , \"add_missing_columns\" : true , \"data_csv_file\" : [{ \"name\" : \"<file name>.csv\" , \"file\" : \"data:text/csv;base64,<File contents base64 here>\" , \"type\" : \"text/csv\" }], \"entity_name\" : \"<entity name>\" } } ' response = requests . post ( 'http://localhost:6336/action/world/upload_csv_to_system_schema' , headers = headers , data = data )","title":"Upload CSV"},{"location":"actions/default_actions/#upload-schema","text":"Upload entity types or actions or any other config to daptin schema_file: json|yaml|toml|hcl restart, system_json_schema_update","title":"Upload schema"},{"location":"actions/default_actions/#download-schema","text":"Download a JSON config of the current daptin instance. This can be imported at a later stage to recreate a similar instance. Note, this contains only the structure and not the actual data. You can take a data dump separately. Or of a particular entity type","title":"Download Schema"},{"location":"actions/default_actions/#become-administrator","text":"Become an admin user of the instance. Only the first user can do this, as long as there is no second user.","title":"Become administrator"},{"location":"actions/default_actions/#sign-up","text":"Sign up a new user, takes in the following parameters name email password passwordConfirm Creates these rows : a new user a new usergroup for the user user belongs to the usergroup","title":"Sign up"},{"location":"actions/default_actions/#sign-in","text":"Sign in essentially generates a [JWT token] issued by Daptin which can be used in requests to authenticate as a user. email password","title":"Sign in"},{"location":"actions/default_actions/#oauth-login","text":"Authenticate via OAuth, this will redirect you to the oauth sign in page of the oauth connection. The response will be handeled by oauth login response","title":"Oauth login"},{"location":"actions/default_actions/#oauth-login-response","text":"This action is supposed to handle the oauth login response flow and not supposed to be invoked manually. Takes in the following parameters (standard oauth2 params) - code - state - authenticator Creates : oauth profile exchange: generate a token from oauth provider stores the oauth token + refresh token for later user","title":"Oauth login response"},{"location":"actions/default_actions/#add-data-exchange","text":"Add new data sync with google-sheets name sheet_id app_key Creates a data exchange","title":"Add data exchange"},{"location":"actions/examples/","text":"Examples Link Actions are entity dependent APIs which you want to expose which may have an outcome of events. Most basic example is the login action which generates an oauth2 token as an outcome. Use action to expose endpoints for your forms and processes. Here is an example of creating a \"/action/project/new_task\" API: New task action YAML Actions : - Name : new_task Label : New to do OnType : project InstanceOptional : true InFields : - ColumnName : description Name : Description ColumnType : label - ColumnName : schedule Name : Scheduled at ColumnType : date OutFields : - Type : todo Method : POST Attributes : schedule : \"~schedule\" title : \"~description\" project_id : \"$.reference_id\" - Type : client.notify Method : ACTIONRESPONSE Attributes : type : success message : Created new todo, taking you to it. title : Wait for it New task action JSON { \"Actions\" : [ { \"Name\" : \"new_task\" , \"Label\" : \"New to do\" , \"OnType\" : \"project\" , \"InstanceOptional\" : true , \"InFields\" : [ { \"ColumnName\" : \"description\" , \"Name\" : \"Description\" , \"ColumnType\" : \"label\" }, { \"ColumnName\" : \"schedule\" , \"Name\" : \"Scheduled at\" , \"ColumnType\" : \"date\" } ], \"OutFields\" : [ { \"Type\" : \"todo\" , \"Method\" : \"POST\" , \"Attributes\" : { \"schedule\" : \"~schedule\" , \"title\" : \"~description\" , \"project_id\" : \"$.reference_id\" } }, { \"Type\" : \"client.notify\" , \"Method\" : \"ACTIONRESPONSE\" , \"Attributes\" : { \"type\" : \"success\" , \"message\" : \"Created new todo, taking you to it.\" , \"title\" : \"Wait for it\" } } ] } ] }","title":"Examples"},{"location":"actions/examples/#examples","text":"Actions are entity dependent APIs which you want to expose which may have an outcome of events. Most basic example is the login action which generates an oauth2 token as an outcome. Use action to expose endpoints for your forms and processes. Here is an example of creating a \"/action/project/new_task\" API: New task action YAML Actions : - Name : new_task Label : New to do OnType : project InstanceOptional : true InFields : - ColumnName : description Name : Description ColumnType : label - ColumnName : schedule Name : Scheduled at ColumnType : date OutFields : - Type : todo Method : POST Attributes : schedule : \"~schedule\" title : \"~description\" project_id : \"$.reference_id\" - Type : client.notify Method : ACTIONRESPONSE Attributes : type : success message : Created new todo, taking you to it. title : Wait for it New task action JSON { \"Actions\" : [ { \"Name\" : \"new_task\" , \"Label\" : \"New to do\" , \"OnType\" : \"project\" , \"InstanceOptional\" : true , \"InFields\" : [ { \"ColumnName\" : \"description\" , \"Name\" : \"Description\" , \"ColumnType\" : \"label\" }, { \"ColumnName\" : \"schedule\" , \"Name\" : \"Scheduled at\" , \"ColumnType\" : \"date\" } ], \"OutFields\" : [ { \"Type\" : \"todo\" , \"Method\" : \"POST\" , \"Attributes\" : { \"schedule\" : \"~schedule\" , \"title\" : \"~description\" , \"project_id\" : \"$.reference_id\" } }, { \"Type\" : \"client.notify\" , \"Method\" : \"ACTIONRESPONSE\" , \"Attributes\" : { \"type\" : \"success\" , \"message\" : \"Created new todo, taking you to it.\" , \"title\" : \"Wait for it\" } } ] } ] }","title":"Examples"},{"location":"apis/crud/","text":"API reference Link Daptin exposes various endpoints for each entity defined in the schema: Create Find one Update Delete Find all Find relations Execute action Aggregate State management All endpoints are protected using the JWT token. API Overview Link CRUD API Link Read/Create/Update/Delete GET /api/{entityName} Query Params Request Body Description GET /api/{entityName} page[size]= page[number] query filter Description POST /api/{entityName} Find all rows, paginated with query and filters PATCH /api/{entityName}/{id} {\"attributes\": { ...{fields} } \"type\": \"{entityType} } Update row by reference id PUT /api/{entityName}/{id} {\"attributes\": { } \"type\": \"{entityType} } Update row by reference id DELETE /api/{entityName}/{id} Delete a row Action API Link GET /action/{entityName}/{actionName} Query Params Request Body Description POST /api/{entityName}/ action parameters Action Parameters Execute action Relation APIs Link Method Path Query params Request body Description GET /api/{entityName}/{id}/{relationName} page[size]= page[number] query filter Find all related rows by relation name, eg, \"posts\" of a user DELETE /api/{entityName}/{id}/{relationName} {\"id\": , \"type\": } Delete a related row, eg: delete post of a user. this only removes a relation and not the actual row. GET /action/{entityName}/{actionName} Parameters for action Invoke an action on an entity POST /action/{entityName}/{actionName} { \"attribute\": { Parameters for action }, \"id\": \"< object id >\" type: \"< entity type >\" } Invoke an action on an entity Aggregate API Link Method Path Query params Request body Description GET /stats/{typeName} group/filter/join/column/timestamp/timefrom/timeto/order Run aggregate function over entity table State machine APIs Link Enabled for the entities for which you have enabled state machines Method Path Query params Request body Description POST /track/start/{stateMachineId} { \"id\": \" < reference id >\", type: \" < entity type > \" } Start tracking according to the state machine for an object POST /track/event/{typename}/{objectStateId}/{eventName} Invoke an event on a particular track of the state machine for a object Websocket API (wip) Link Listed to incoming updates to data over websocket live Method Path Query params Request body Description GET /live Initiate a web socket connection Metadata API Link Use metadata to build and design your appliction in a more intuitive way Method Path Query params Request body Description GET /apispec.raml RAML Spec for all API's GET /ping Replies with PONG, Good for liveness probe GET /statistics Replies with PONG, Good for liveness probe Read Link Parameters Link Name parameter type default value example value page[number] integer 1 5 page[size] integer 10 100 query json base64 [] [{\"column\": \"name\", \"operator\": \"is\", \"value\": \"england\"}] group string - [{\"column\": \"name\", \"order\": \"desc\"}] included_relations comma separated string - user post author sort comma seaparated string - created_at amount guest_count filter string - england Response Link Response example { \"links\": { \"current_page\": 1, \"from\": 0, \"last_page\": 1, \"per_page\": 10, \"to\": 10, \"total\": 1 }, \"data\": [{ \"type\": \"book\", \"id\": \"29d11cb3-3fad-4972-bf3b-9cfc6da9e6a6\", \"attributes\": { \"__type\": \"book\", \"confirmed\": 0, \"created_at\": \"2018-04-05 15:47:29\", \"title\": \"book title\", \"name\": \"book name\", \"permission\": 127127127, \"reference_id\": \"29d11cb3-3fad-4972-bf3b-9cfc6da9e6a6\", \"updated_at\": null, \"user_id\": \"696c98d3-3b8b-41da-a510-08e6948cf661\" }, \"relationships\": { \"author_id\": { \"links\": { \"related\": \"/api/book/<book-id/author_id\", \"self\": \"/api/book/<book-id>/relationships/author_id\" }, \"data\": [] } } }] } Examples Link Curl example Link curl '/api/&lt;entityName&gt;?sort=&amp;page [ number ] =1&amp;page [ size ] =10' \\ -H 'Authorization: Bearer &lt;AccessToken&gt;' jQuery ajax example Link $ . ajax ( { method : \"GET\" , url : '/api/&lt;entityName&gt;?sort=&amp;page [ number ] =1&amp;page [ size ] =10' , success : function ( response ) { console . log ( response . data ); } } ) Node js example Link var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer &lt;AccessToken&gt;' }; var options = { url : '/api/&lt;entityName&gt;?sort=&amp;page[number]=1&amp;page[size]=10' , headers : headers }; function callback ( error , response , body ) { if ( ! error & amp ; & amp ; response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); Python example Link import requests headers = { 'Authorization' : 'Bearer &lt;AccessToken&gt;' , } params = ( ( 'sort' , '-created_at' ), ( 'page[number]' , '1' ), ( 'page[size]' , '10' ), ) response = requests . get ( 'http://localhost:6336/api/laptop' , headers = headers , params = params ) PHP example Link & lt ;? php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $ headers = array ( 'Authorization' =& gt ; 'Bearer &lt;AccessToken&gt;' ); $ response = Requests :: get ( 'http://localhost:6336/api/laptop?sort=&amp;page [ number ] =1&amp;page [ size ] =10' , $ headers ); Filtering Link Used to search items in a table that matche the filter's conditions. Filters follow the syntax query=[{\"column\": \"<column_name>\", \"operator\": \"<compare-operator>\", \"value\":\"<value>\"}] Daptin operator SQL compare operator contains like '%\\ ' not contains not like '%\\ ' is = is not != before < less then < after > more then > any of in none of not in is empty is null is not empty is not null Example Link curl '/api/world?query= [ { \"column\" : \"is_hidden\" , \"operator\" : \"any of\" , \"value\" : \"1,0\" } ] \\ -H ' Authorization : Bearer & lt ; AccessToken & gt ; ' Create Link !!! note \"Curl Example\" curl '/api/<EntityName>' -H 'Authorization: Bearer <Token>' --data-binary '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"name\": \"name\" } } }' !!! note \"Nodejs example\" var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer <Token>' , }; var dataString = '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"name\": \"name\" } } }' ; var options = { url : '/api/<EntityName>' , method : 'POST' , headers : headers , body : dataString }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); !!! note \"Python example\" import requests headers = { 'Authorization' : 'Bearer <Token>' , } data = '{ \"data\" : { \"type\" : \"<EntityName>\" , \"attributes\" : { \"name\" : \"name\" } } } ' response = requests . post ( '/api/<EntityName>' , headers = headers , data = data ) !!! note \"PHP Example\" <?php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $headers = array ( 'Authorization' => 'Bearer <Token>' , ); $data = '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"name\": \"name\" } } }' ; $response = Requests :: post ( '/api/<EntityName>' , $headers , $data ); Update Link Curl example curl '/api/<EntityName>/<ReferenceId>' -X PATCH -H 'Authorization: Bearer <Token>' --data-binary '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"confirmed\": false, \"email\": \"update@gmail.com\", \"name\": \"new name\", \"password\": \"\", \"permission\": 127127127, }, \"relationships\": { \"relation_name\": [ ... ] }, \"id\": \"<ReferenceId>\" } }' Nodejs example var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer <Token>' }; var dataString = '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"confirmed\": false, \"email\": \"update@gmail.com\", \"name\": \"new name\", \"password\": \"\", \"permission\": 127127127, }, \"relationships\": { \"relation_name\": [ ... ] }, \"id\": \"<ReferenceId>\" } }' ; var options = { url : '/api/<EntityName>/<ReferenceId>' , method : 'PATCH' , headers : headers , body : dataString }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); Python example import requests headers = { 'Authorization' : 'Bearer <Token>' , } data = '{ \"data\" : { \"type\" : \"<EntityName>\" , \"attributes\" : { \"confirmed\" : false , \"email\" : \"update@gmail.com\" , \"name\" : \"new name\" , \"password\" : \"\" , \"permission\" : 127127127 , }, \"relationships\" : { \"relation_name\" : [ ... ] }, \"id\" : \"<ReferenceId>\" } } ' response = requests . patch ( '/api/<EntityName>/<ReferenceId>' , headers = headers , data = data ) PHP example <?php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $headers = array ( 'Authorization' => 'Bearer <Token>' ); $data = '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"confirmed\": false, \"email\": \"update@gmail.com\", \"name\": \"new name\", \"password\": \"\", \"permission\": 127127127, }, \"relationships\": { \"relation_name\": [ ... ] }, \"id\": \"<ReferenceId>\" } }' ; $response = Requests :: patch ( '/api/<EntityName>/<ReferenceId>' , $headers , $data ); Delete Link Delete a row from a table Curl example curl '/api/user_account/a5b9add2-ea56-4717-a785-7dee71a2ae46' -X DELETE -H 'Authorization: Bearer <Token>' Nodejs example var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer <Token>' }; var options = { url : '/api/user_account/a5b9add2-ea56-4717-a785-7dee71a2ae46' , method : 'DELETE' , headers : headers }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); Python example import requests headers = { 'Authorization' : 'Bearer <Token>' , } response = requests . delete ( '/api/user_account/a5b9add2-ea56-4717-a785-7dee71a2ae46' , headers = headers ) PHP example <?php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $headers = array ( 'Authorization' => 'Bearer <Token>' ); $response = Requests :: delete ( '/api/user_account/a5b9add2-ea56-4717-a785-7dee71a2ae46' , $headers ); Execute Link Execute an action on an entity type or instance Curl example curl '/action/<EntityName>/<ActionName>' -H 'Authorization: Bearer <Token>' --data-binary '{\"attributes\":{}}' PHP Example <?php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $headers = array ( 'Authorization' => 'Bearer <Token>' ); $data = '{\"attributes\":{}}' ; $response = Requests :: post ( '/action/<EntityName>/<ActionName>' , $headers , $data ); Nodejs example var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer <Token>' }; var dataString = '{\"attributes\":{}}' ; var options = { url : '/action/<EntityName>/<ActionName>' , method : 'POST' , headers : headers , body : dataString }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); Python example import requests headers = { 'Authorization' : 'Bearer <Token>' , } data = '{\"attributes\":{}}' response = requests . post ( '/action/<EntityName>/<ActionName>' , headers = headers , data = data ) Relations Link curl example curl '/api/<EntityName>/<ReferenceId>/<RelationName>?sort=&page[number]=1&page[size]=10' -H 'Authorization: Bearer <Token>' php example <?php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $headers = array ( 'Authorization' => 'Bearer <Token>' ); python example import requests headers = { 'Authorization' : 'Bearer <Token>' , } params = ( ( 'sort' , '' ), ( 'page/[number/]' , '1' ), ( 'page/[size/]' , '10' ), ) response = requests . get ( 'http://localhost:6336/api/user_account/696c98d3-3b8b-41da-a510-08e6948cf661/marketplace_id' , headers = headers , params = params ) #NB. Original query string below. It seems impossible to parse and #reproduce query strings 100% accurately so the one below is given #in case the reproduced version is not \"correct\". # response = requests.get('http://localhost:6336/api/user_account/696c98d3-3b8b-41da-a510-08e6948cf661/marketplace_id?sort=&page\\[number\\]=1&page\\[size\\]=10', headers=headers) nodejs example var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer <Token>' }; var options = { url : '/api/<EntityName>/<ReferenceId>/<RelationName>?sort=&page[number]=1&page[size]=10' , headers : headers }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); python example import requests headers = { 'Authorization' : 'Bearer <Token>' , } params = ( ( 'sort' , '' ), ( 'page[number]' , '1' ), ( 'page[size]' , '10' ), ) response = requests . get ( '/api/<EntityName>/<ReferenceId>/<RelationName>' , headers = headers , params = params )","title":"API reference"},{"location":"apis/crud/#api-reference","text":"Daptin exposes various endpoints for each entity defined in the schema: Create Find one Update Delete Find all Find relations Execute action Aggregate State management All endpoints are protected using the JWT token.","title":"API reference"},{"location":"apis/crud/#api-overview","text":"","title":"API Overview"},{"location":"apis/crud/#crud-api","text":"Read/Create/Update/Delete GET /api/{entityName} Query Params Request Body Description GET /api/{entityName} page[size]= page[number] query filter Description POST /api/{entityName} Find all rows, paginated with query and filters PATCH /api/{entityName}/{id} {\"attributes\": { ...{fields} } \"type\": \"{entityType} } Update row by reference id PUT /api/{entityName}/{id} {\"attributes\": { } \"type\": \"{entityType} } Update row by reference id DELETE /api/{entityName}/{id} Delete a row","title":"CRUD API"},{"location":"apis/crud/#action-api","text":"GET /action/{entityName}/{actionName} Query Params Request Body Description POST /api/{entityName}/ action parameters Action Parameters Execute action","title":"Action API"},{"location":"apis/crud/#relation-apis","text":"Method Path Query params Request body Description GET /api/{entityName}/{id}/{relationName} page[size]= page[number] query filter Find all related rows by relation name, eg, \"posts\" of a user DELETE /api/{entityName}/{id}/{relationName} {\"id\": , \"type\": } Delete a related row, eg: delete post of a user. this only removes a relation and not the actual row. GET /action/{entityName}/{actionName} Parameters for action Invoke an action on an entity POST /action/{entityName}/{actionName} { \"attribute\": { Parameters for action }, \"id\": \"< object id >\" type: \"< entity type >\" } Invoke an action on an entity","title":"Relation APIs"},{"location":"apis/crud/#aggregate-api","text":"Method Path Query params Request body Description GET /stats/{typeName} group/filter/join/column/timestamp/timefrom/timeto/order Run aggregate function over entity table","title":"Aggregate API"},{"location":"apis/crud/#state-machine-apis","text":"Enabled for the entities for which you have enabled state machines Method Path Query params Request body Description POST /track/start/{stateMachineId} { \"id\": \" < reference id >\", type: \" < entity type > \" } Start tracking according to the state machine for an object POST /track/event/{typename}/{objectStateId}/{eventName} Invoke an event on a particular track of the state machine for a object","title":"State machine APIs"},{"location":"apis/crud/#websocket-api-wip","text":"Listed to incoming updates to data over websocket live Method Path Query params Request body Description GET /live Initiate a web socket connection","title":"Websocket API (wip)"},{"location":"apis/crud/#metadata-api","text":"Use metadata to build and design your appliction in a more intuitive way Method Path Query params Request body Description GET /apispec.raml RAML Spec for all API's GET /ping Replies with PONG, Good for liveness probe GET /statistics Replies with PONG, Good for liveness probe","title":"Metadata API"},{"location":"apis/crud/#read","text":"","title":"Read"},{"location":"apis/crud/#parameters","text":"Name parameter type default value example value page[number] integer 1 5 page[size] integer 10 100 query json base64 [] [{\"column\": \"name\", \"operator\": \"is\", \"value\": \"england\"}] group string - [{\"column\": \"name\", \"order\": \"desc\"}] included_relations comma separated string - user post author sort comma seaparated string - created_at amount guest_count filter string - england","title":"Parameters"},{"location":"apis/crud/#response","text":"Response example { \"links\": { \"current_page\": 1, \"from\": 0, \"last_page\": 1, \"per_page\": 10, \"to\": 10, \"total\": 1 }, \"data\": [{ \"type\": \"book\", \"id\": \"29d11cb3-3fad-4972-bf3b-9cfc6da9e6a6\", \"attributes\": { \"__type\": \"book\", \"confirmed\": 0, \"created_at\": \"2018-04-05 15:47:29\", \"title\": \"book title\", \"name\": \"book name\", \"permission\": 127127127, \"reference_id\": \"29d11cb3-3fad-4972-bf3b-9cfc6da9e6a6\", \"updated_at\": null, \"user_id\": \"696c98d3-3b8b-41da-a510-08e6948cf661\" }, \"relationships\": { \"author_id\": { \"links\": { \"related\": \"/api/book/<book-id/author_id\", \"self\": \"/api/book/<book-id>/relationships/author_id\" }, \"data\": [] } } }] }","title":"Response"},{"location":"apis/crud/#examples","text":"","title":"Examples"},{"location":"apis/crud/#curl-example","text":"curl '/api/&lt;entityName&gt;?sort=&amp;page [ number ] =1&amp;page [ size ] =10' \\ -H 'Authorization: Bearer &lt;AccessToken&gt;'","title":"Curl example"},{"location":"apis/crud/#jquery-ajax-example","text":"$ . ajax ( { method : \"GET\" , url : '/api/&lt;entityName&gt;?sort=&amp;page [ number ] =1&amp;page [ size ] =10' , success : function ( response ) { console . log ( response . data ); } } )","title":"jQuery ajax example"},{"location":"apis/crud/#node-js-example","text":"var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer &lt;AccessToken&gt;' }; var options = { url : '/api/&lt;entityName&gt;?sort=&amp;page[number]=1&amp;page[size]=10' , headers : headers }; function callback ( error , response , body ) { if ( ! error & amp ; & amp ; response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback );","title":"Node js example"},{"location":"apis/crud/#python-example","text":"import requests headers = { 'Authorization' : 'Bearer &lt;AccessToken&gt;' , } params = ( ( 'sort' , '-created_at' ), ( 'page[number]' , '1' ), ( 'page[size]' , '10' ), ) response = requests . get ( 'http://localhost:6336/api/laptop' , headers = headers , params = params )","title":"Python example"},{"location":"apis/crud/#php-example","text":"& lt ;? php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $ headers = array ( 'Authorization' =& gt ; 'Bearer &lt;AccessToken&gt;' ); $ response = Requests :: get ( 'http://localhost:6336/api/laptop?sort=&amp;page [ number ] =1&amp;page [ size ] =10' , $ headers );","title":"PHP example"},{"location":"apis/crud/#filtering","text":"Used to search items in a table that matche the filter's conditions. Filters follow the syntax query=[{\"column\": \"<column_name>\", \"operator\": \"<compare-operator>\", \"value\":\"<value>\"}] Daptin operator SQL compare operator contains like '%\\ ' not contains not like '%\\ ' is = is not != before < less then < after > more then > any of in none of not in is empty is null is not empty is not null","title":"Filtering"},{"location":"apis/crud/#example","text":"curl '/api/world?query= [ { \"column\" : \"is_hidden\" , \"operator\" : \"any of\" , \"value\" : \"1,0\" } ] \\ -H ' Authorization : Bearer & lt ; AccessToken & gt ; '","title":"Example"},{"location":"apis/crud/#create","text":"!!! note \"Curl Example\" curl '/api/<EntityName>' -H 'Authorization: Bearer <Token>' --data-binary '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"name\": \"name\" } } }' !!! note \"Nodejs example\" var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer <Token>' , }; var dataString = '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"name\": \"name\" } } }' ; var options = { url : '/api/<EntityName>' , method : 'POST' , headers : headers , body : dataString }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); !!! note \"Python example\" import requests headers = { 'Authorization' : 'Bearer <Token>' , } data = '{ \"data\" : { \"type\" : \"<EntityName>\" , \"attributes\" : { \"name\" : \"name\" } } } ' response = requests . post ( '/api/<EntityName>' , headers = headers , data = data ) !!! note \"PHP Example\" <?php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $headers = array ( 'Authorization' => 'Bearer <Token>' , ); $data = '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"name\": \"name\" } } }' ; $response = Requests :: post ( '/api/<EntityName>' , $headers , $data );","title":"Create"},{"location":"apis/crud/#update","text":"Curl example curl '/api/<EntityName>/<ReferenceId>' -X PATCH -H 'Authorization: Bearer <Token>' --data-binary '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"confirmed\": false, \"email\": \"update@gmail.com\", \"name\": \"new name\", \"password\": \"\", \"permission\": 127127127, }, \"relationships\": { \"relation_name\": [ ... ] }, \"id\": \"<ReferenceId>\" } }' Nodejs example var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer <Token>' }; var dataString = '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"confirmed\": false, \"email\": \"update@gmail.com\", \"name\": \"new name\", \"password\": \"\", \"permission\": 127127127, }, \"relationships\": { \"relation_name\": [ ... ] }, \"id\": \"<ReferenceId>\" } }' ; var options = { url : '/api/<EntityName>/<ReferenceId>' , method : 'PATCH' , headers : headers , body : dataString }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); Python example import requests headers = { 'Authorization' : 'Bearer <Token>' , } data = '{ \"data\" : { \"type\" : \"<EntityName>\" , \"attributes\" : { \"confirmed\" : false , \"email\" : \"update@gmail.com\" , \"name\" : \"new name\" , \"password\" : \"\" , \"permission\" : 127127127 , }, \"relationships\" : { \"relation_name\" : [ ... ] }, \"id\" : \"<ReferenceId>\" } } ' response = requests . patch ( '/api/<EntityName>/<ReferenceId>' , headers = headers , data = data ) PHP example <?php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $headers = array ( 'Authorization' => 'Bearer <Token>' ); $data = '{ \"data\": { \"type\": \"<EntityName>\", \"attributes\": { \"confirmed\": false, \"email\": \"update@gmail.com\", \"name\": \"new name\", \"password\": \"\", \"permission\": 127127127, }, \"relationships\": { \"relation_name\": [ ... ] }, \"id\": \"<ReferenceId>\" } }' ; $response = Requests :: patch ( '/api/<EntityName>/<ReferenceId>' , $headers , $data );","title":"Update"},{"location":"apis/crud/#delete","text":"Delete a row from a table Curl example curl '/api/user_account/a5b9add2-ea56-4717-a785-7dee71a2ae46' -X DELETE -H 'Authorization: Bearer <Token>' Nodejs example var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer <Token>' }; var options = { url : '/api/user_account/a5b9add2-ea56-4717-a785-7dee71a2ae46' , method : 'DELETE' , headers : headers }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); Python example import requests headers = { 'Authorization' : 'Bearer <Token>' , } response = requests . delete ( '/api/user_account/a5b9add2-ea56-4717-a785-7dee71a2ae46' , headers = headers ) PHP example <?php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $headers = array ( 'Authorization' => 'Bearer <Token>' ); $response = Requests :: delete ( '/api/user_account/a5b9add2-ea56-4717-a785-7dee71a2ae46' , $headers );","title":"Delete"},{"location":"apis/crud/#execute","text":"Execute an action on an entity type or instance Curl example curl '/action/<EntityName>/<ActionName>' -H 'Authorization: Bearer <Token>' --data-binary '{\"attributes\":{}}' PHP Example <?php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $headers = array ( 'Authorization' => 'Bearer <Token>' ); $data = '{\"attributes\":{}}' ; $response = Requests :: post ( '/action/<EntityName>/<ActionName>' , $headers , $data ); Nodejs example var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer <Token>' }; var dataString = '{\"attributes\":{}}' ; var options = { url : '/action/<EntityName>/<ActionName>' , method : 'POST' , headers : headers , body : dataString }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); Python example import requests headers = { 'Authorization' : 'Bearer <Token>' , } data = '{\"attributes\":{}}' response = requests . post ( '/action/<EntityName>/<ActionName>' , headers = headers , data = data )","title":"Execute"},{"location":"apis/crud/#relations","text":"curl example curl '/api/<EntityName>/<ReferenceId>/<RelationName>?sort=&page[number]=1&page[size]=10' -H 'Authorization: Bearer <Token>' php example <?php include ( 'vendor/rmccue/requests/library/Requests.php' ); Requests :: register_autoloader (); $headers = array ( 'Authorization' => 'Bearer <Token>' ); python example import requests headers = { 'Authorization' : 'Bearer <Token>' , } params = ( ( 'sort' , '' ), ( 'page/[number/]' , '1' ), ( 'page/[size/]' , '10' ), ) response = requests . get ( 'http://localhost:6336/api/user_account/696c98d3-3b8b-41da-a510-08e6948cf661/marketplace_id' , headers = headers , params = params ) #NB. Original query string below. It seems impossible to parse and #reproduce query strings 100% accurately so the one below is given #in case the reproduced version is not \"correct\". # response = requests.get('http://localhost:6336/api/user_account/696c98d3-3b8b-41da-a510-08e6948cf661/marketplace_id?sort=&page\\[number\\]=1&page\\[size\\]=10', headers=headers) nodejs example var request = require ( 'request' ); var headers = { 'Authorization' : 'Bearer <Token>' }; var options = { url : '/api/<EntityName>/<ReferenceId>/<RelationName>?sort=&page[number]=1&page[size]=10' , headers : headers }; function callback ( error , response , body ) { if ( ! error && response . statusCode == 200 ) { console . log ( body ); } } request ( options , callback ); python example import requests headers = { 'Authorization' : 'Bearer <Token>' , } params = ( ( 'sort' , '' ), ( 'page[number]' , '1' ), ( 'page[size]' , '10' ), ) response = requests . get ( '/api/<EntityName>/<ReferenceId>/<RelationName>' , headers = headers , params = params )","title":"Relations"},{"location":"cloudstore/assetcolumns/","text":"Asset columns Link Column types of blob types can either be stored in the database itself (not recommended) or persist in a persistent storage. After we have created a cloud store , we can point the column to a folder on the cloud store. The column will only contain metadata and the actual file will be persisted on the cloud store. To enable this, update the ForeignKeyData config of the column as follows: Create a file for the schema change: Tables : - TableName : < TableNameHere > - Columns : - ColumnName : < ColumnNameHere > ForeignKeyData : DataSource : \"cloud\" KeyName : < Cloud store name here > Namespace : < Folder name inside that clouds store > Upload it using the dashboard (You can alternatively just edit that from the dashboard). This will trigger a reconfiguration of the system and initiate a local sync of the cloud directory in a temporary location. The cloud directory will be synced down stream every 15 minutes while the uploads will be asynced but instantaneous. Such columns like image./video./audio./markdown. will be served over HTTP in a simple GET call: /asset/<table_name>/<reference_id>/<column_name>.<extension> <extension> can be anything relevant to the mimetype of the file. The column file will be dumped as it is. Useful for using in img html tag.","title":"Cloud store backed asset columns"},{"location":"cloudstore/assetcolumns/#asset-columns","text":"Column types of blob types can either be stored in the database itself (not recommended) or persist in a persistent storage. After we have created a cloud store , we can point the column to a folder on the cloud store. The column will only contain metadata and the actual file will be persisted on the cloud store. To enable this, update the ForeignKeyData config of the column as follows: Create a file for the schema change: Tables : - TableName : < TableNameHere > - Columns : - ColumnName : < ColumnNameHere > ForeignKeyData : DataSource : \"cloud\" KeyName : < Cloud store name here > Namespace : < Folder name inside that clouds store > Upload it using the dashboard (You can alternatively just edit that from the dashboard). This will trigger a reconfiguration of the system and initiate a local sync of the cloud directory in a temporary location. The cloud directory will be synced down stream every 15 minutes while the uploads will be asynced but instantaneous. Such columns like image./video./audio./markdown. will be served over HTTP in a simple GET call: /asset/<table_name>/<reference_id>/<column_name>.<extension> <extension> can be anything relevant to the mimetype of the file. The column file will be dumped as it is. Useful for using in img html tag.","title":"Asset columns"},{"location":"cloudstore/cloudstore/","text":"Cloud store Link Datin can work with the following storage services: Amazon Drive Amazon S3 Backblaze B2 Box Ceph DigitalOcean Spaces Dreamhost Dropbox FTP Google Cloud Storage Google Drive HTTP Hubic Memset Memstore Microsoft Azure Blob Storage Microsoft OneDrive Minio Nextloud OVH Openstack Swift Oracle Cloud Storage Ownloud pCloud put.io QingStor Rackspace Cloud Files SFTP Wasabi WebDAV Yandex Disk The local filesystem Creating a new cloud storage instance Link Things to keep ready Link If the service you wan to integrate with requires authentication, create the following: An oauth connection An oauth token generated from the above connection Steps Link Login to the dashboard Click \"Storage\" tile Click the green \"+\" icon on the top right Use the name to identify it uniquely Root Path : in rclone format, eg gdrive: drive:directory/subdirectory dropbox/ftp/local: remote/local:directory/subdirectory Store Provider : dropbox/drive/local/ftp... Store Type : cloud/local","title":"Cloud store"},{"location":"cloudstore/cloudstore/#cloud-store","text":"Datin can work with the following storage services: Amazon Drive Amazon S3 Backblaze B2 Box Ceph DigitalOcean Spaces Dreamhost Dropbox FTP Google Cloud Storage Google Drive HTTP Hubic Memset Memstore Microsoft Azure Blob Storage Microsoft OneDrive Minio Nextloud OVH Openstack Swift Oracle Cloud Storage Ownloud pCloud put.io QingStor Rackspace Cloud Files SFTP Wasabi WebDAV Yandex Disk The local filesystem","title":"Cloud store"},{"location":"cloudstore/cloudstore/#creating-a-new-cloud-storage-instance","text":"","title":"Creating a new cloud storage instance"},{"location":"cloudstore/cloudstore/#things-to-keep-ready","text":"If the service you wan to integrate with requires authentication, create the following: An oauth connection An oauth token generated from the above connection","title":"Things to keep ready"},{"location":"cloudstore/cloudstore/#steps","text":"Login to the dashboard Click \"Storage\" tile Click the green \"+\" icon on the top right Use the name to identify it uniquely Root Path : in rclone format, eg gdrive: drive:directory/subdirectory dropbox/ftp/local: remote/local:directory/subdirectory Store Provider : dropbox/drive/local/ftp... Store Type : cloud/local","title":"Steps"},{"location":"data-modeling/data_storage/","text":"Data storage Link Daptin relies on a relational database for all data persistence requirements. As covered in the installation currently the following relational database are supported: MySQL PostgreSQL SQLite This document goes into the detail of how the database is used and what are the tables created. Standard columns Link The following 5 columns are present in every table ColumnName ColumnType DataType Attributes id id int(11) primary key Auto increment Never exposed externally version integer int(11) get incremented every time a change is made created_at timestamp timestamp the timestamp when the row was created updated_at timestamp timestamp the timestamp when the row was last updated reference_id alias varchar(40) The id exposed in APIs permission integer int(4) Permissions - check Authorization documentation user_id foreign key int(11) the owner of this object Other columns are created based on the schema. The id column is completely for internal purposes and is never exposed in an JSON API. Every row of data inherently belongs to one user. This is the user who created that row. The associated user can be changed later. World table Link The world table holds the structure for all the entities and relations (including for itself). Each row contains the schema for the table in a \"world_schema_json\" column.","title":"Data store format"},{"location":"data-modeling/data_storage/#data-storage","text":"Daptin relies on a relational database for all data persistence requirements. As covered in the installation currently the following relational database are supported: MySQL PostgreSQL SQLite This document goes into the detail of how the database is used and what are the tables created.","title":"Data storage"},{"location":"data-modeling/data_storage/#standard-columns","text":"The following 5 columns are present in every table ColumnName ColumnType DataType Attributes id id int(11) primary key Auto increment Never exposed externally version integer int(11) get incremented every time a change is made created_at timestamp timestamp the timestamp when the row was created updated_at timestamp timestamp the timestamp when the row was last updated reference_id alias varchar(40) The id exposed in APIs permission integer int(4) Permissions - check Authorization documentation user_id foreign key int(11) the owner of this object Other columns are created based on the schema. The id column is completely for internal purposes and is never exposed in an JSON API. Every row of data inherently belongs to one user. This is the user who created that row. The associated user can be changed later.","title":"Standard columns"},{"location":"data-modeling/data_storage/#world-table","text":"The world table holds the structure for all the entities and relations (including for itself). Each row contains the schema for the table in a \"world_schema_json\" column.","title":"World table"},{"location":"extend/data_exchange/","text":"Data Exchanges Link Exchanges are internal hooks to external apis, to either push data and update an external service, or pull data and update itself from some external service. Example, use exchange to sync data creation call to Google Sheets. So on every row created using the POST API also creates a corresponding row in your google sheet. Google drive exchange YAML Exchanges : - Name : Task to excel sheet SourceAttributes : Name : todo SourceType : self TargetAttributes : sheetUrl : https://content-sheets.googleapis.com/v4/spreadsheets/1Ru-bDk3AjQotQj72k8SyxoOs84eXA1Y6sSPumBb3WSA/values/A1:append appKey : AIzaSyAC2xame4NShrzH9ZJeEpWT5GkySooa0XM TargetType : gsheet-append Attributes : - SourceColumn : \"$self.description\" TargetColumn : Task description - SourceColumn : self.schedule TargetColumn : Scheduled at Options : hasHeader : true","title":"Data exchange and sync"},{"location":"extend/data_exchange/#data-exchanges","text":"Exchanges are internal hooks to external apis, to either push data and update an external service, or pull data and update itself from some external service. Example, use exchange to sync data creation call to Google Sheets. So on every row created using the POST API also creates a corresponding row in your google sheet. Google drive exchange YAML Exchanges : - Name : Task to excel sheet SourceAttributes : Name : todo SourceType : self TargetAttributes : sheetUrl : https://content-sheets.googleapis.com/v4/spreadsheets/1Ru-bDk3AjQotQj72k8SyxoOs84eXA1Y6sSPumBb3WSA/values/A1:append appKey : AIzaSyAC2xame4NShrzH9ZJeEpWT5GkySooa0XM TargetType : gsheet-append Attributes : - SourceColumn : \"$self.description\" TargetColumn : Task description - SourceColumn : self.schedule TargetColumn : Scheduled at Options : hasHeader : true","title":"Data Exchanges "},{"location":"extend/oauth_connection/","text":"OAuth Connections Link Daptin is natively aware of oauth2 flows and can seamlessly handle oauth tokens and refresh tokens (if provided). Oauth connection are useful in consuming other parts of daptin easily, like cloud storage, sub-sites, 3rd party logins. To begin using oauth involved flows (eg GoogleDrive as data storage) first daptin needs to be configured about the oauth connection parameters. Creating a new oauth connection Link Log into the dashboard Click the tile \"OAuth connections\" Click the green \"+\" button on the top right Leave \"Allow Login\" unchecked. We can change this later Enter your service's auth endpoint, eg for google its \" https://accounts.google.com/o/oauth2/auth \" Client Id : Client Id generated by the service for daptin Client Secret : Client secret, this will be stored after encryption and wont be retrievable from daptin. Name : Identify it with a name Redirect Uri : Change this to http://<Domain>/oauth/response instead of /oauth/response Response Type : code Scope : Appropriate score defined by the oauth service to access the resource Eg: for gdrive: https://www.googleapis.com/auth/drive for gsheet: https://www.googleapis.com/auth/spreadsheets Token Url : The token info url of the oauth service: eg: https://accounts.google.com/o/oauth2/token Now you can generate a token","title":"OAuth Connections"},{"location":"extend/oauth_connection/#oauth-connections","text":"Daptin is natively aware of oauth2 flows and can seamlessly handle oauth tokens and refresh tokens (if provided). Oauth connection are useful in consuming other parts of daptin easily, like cloud storage, sub-sites, 3rd party logins. To begin using oauth involved flows (eg GoogleDrive as data storage) first daptin needs to be configured about the oauth connection parameters.","title":"OAuth Connections"},{"location":"extend/oauth_connection/#creating-a-new-oauth-connection","text":"Log into the dashboard Click the tile \"OAuth connections\" Click the green \"+\" button on the top right Leave \"Allow Login\" unchecked. We can change this later Enter your service's auth endpoint, eg for google its \" https://accounts.google.com/o/oauth2/auth \" Client Id : Client Id generated by the service for daptin Client Secret : Client secret, this will be stored after encryption and wont be retrievable from daptin. Name : Identify it with a name Redirect Uri : Change this to http://<Domain>/oauth/response instead of /oauth/response Response Type : code Scope : Appropriate score defined by the oauth service to access the resource Eg: for gdrive: https://www.googleapis.com/auth/drive for gsheet: https://www.googleapis.com/auth/spreadsheets Token Url : The token info url of the oauth service: eg: https://accounts.google.com/o/oauth2/token Now you can generate a token","title":"Creating a new oauth connection"},{"location":"extend/oauth_token/","text":"OAuth Tokens Link Oauth tokens can be used internally to connect to other services which require authentication. Tokens and Refresh token are stored with encryption in the database Refresh token is used to generate new tokens if the existing token expires Generate a new token Link Click the \"expand\" icon on the card to go into detailed view On the right side, under the \"Actions\" find \"Authenticate via OAuth\" Click it and click \"Submit\" in the next form to initiate the flow","title":"OAuth Tokens"},{"location":"extend/oauth_token/#oauth-tokens","text":"Oauth tokens can be used internally to connect to other services which require authentication. Tokens and Refresh token are stored with encryption in the database Refresh token is used to generate new tokens if the existing token expires","title":"OAuth Tokens"},{"location":"extend/oauth_token/#generate-a-new-token","text":"Click the \"expand\" icon on the card to go into detailed view On the right side, under the \"Actions\" find \"Authenticate via OAuth\" Click it and click \"Submit\" in the next form to initiate the flow","title":"Generate a new token"},{"location":"features/enable-data-auditing/","text":"todo add documentation","title":"Data Auditing"},{"location":"features/enable-graphql/","text":"Graphql Link By default the GraphQL endpoint is not enabled. If you want to use GraphQL endpoint, here is how you can enable it. Set graphql.enable to true in config: curl \\ -H \"Authorization: Bearer TOKEN\" \\ -X POST http://localhost:6336/_config/backend/graphql.enable --data true You can try to GET it again to verify if it was set or not (in case token is invalid or not set) curl \\ -H \"Authorization: Bearer TOKEN\" \\ http://localhost:6336/_config/backend/graphql.enable You need to restart daptin for this setting to take effect. You can issue a restart by calling this: curl 'http://localhost:6336/action/world/restart_daptin' \\ -H 'Authorization: Bearer TOKEN' \\ --data '{\"attributes\":{}}' If everything goes well, the graphql endpoint should be enabled. You can test it curl http://localhost:6336/graphql Response { \"data\" : null , \"errors\" : [ { \"message\" : \"Must provide an operation.\" , \"locations\" : [] } ] } You can access the iGraphQL console at http://localhost:6336/graphql","title":"GraphQL"},{"location":"features/enable-graphql/#graphql","text":"By default the GraphQL endpoint is not enabled. If you want to use GraphQL endpoint, here is how you can enable it. Set graphql.enable to true in config: curl \\ -H \"Authorization: Bearer TOKEN\" \\ -X POST http://localhost:6336/_config/backend/graphql.enable --data true You can try to GET it again to verify if it was set or not (in case token is invalid or not set) curl \\ -H \"Authorization: Bearer TOKEN\" \\ http://localhost:6336/_config/backend/graphql.enable You need to restart daptin for this setting to take effect. You can issue a restart by calling this: curl 'http://localhost:6336/action/world/restart_daptin' \\ -H 'Authorization: Bearer TOKEN' \\ --data '{\"attributes\":{}}' If everything goes well, the graphql endpoint should be enabled. You can test it curl http://localhost:6336/graphql Response { \"data\" : null , \"errors\" : [ { \"message\" : \"Must provide an operation.\" , \"locations\" : [] } ] } You can access the iGraphQL console at http://localhost:6336/graphql","title":"Graphql"},{"location":"features/enable-logs/","text":"todo add documentation","title":"Logs"},{"location":"features/enable-multilingual-table/","text":"todo add documentation","title":"Multilingual Table"},{"location":"features/enable-smtp-imap/","text":"todo add documentation","title":"SMTP/IMPS server"},{"location":"guides/todo_example/","text":"","title":"Todo example"},{"location":"integrations/overview/","text":"Integrations overview Link You can import any OpenAPI v2/v3 spec and later use defined methods to compose actions for integration with 3rd API services. Example Todo: Add exmaple Accepting payments with Stripe Todo: Add exmaple 2fa OTP","title":"Integrations Overview"},{"location":"integrations/overview/#integrations-overview","text":"You can import any OpenAPI v2/v3 spec and later use defined methods to compose actions for integration with 3rd API services. Example Todo: Add exmaple Accepting payments with Stripe Todo: Add exmaple 2fa OTP","title":"Integrations overview"},{"location":"reference/database_configuration/","text":"","title":"Database configuration"},{"location":"setting-up/access/","text":"User management Link Daptin maintains its own User accounts and User groups entries in the database. Users are identified by email which is a unique key in the user_account entity. Passwords are stored using bcrypt with a cost of 11. Password field has a column_type password which makes daptin to bcrypt it before storing, and password fields are never returned in any JSONAPI call. Authentication Link Authentication involves identifying the current user of the request. Daptin expectes a JWT token issued at signin as Authorization: Bearer <Token> header, otherwise the request is considered coming from a guest . Sign Up Link Sign up is an action on user entity. Sign up takes four inputs: Name Email Password PasswordConfirm When the user initiates a Sign up action, the following things happen Check if guests can initiate sign in action Check if guests can create a new user (create permission) Create a new user row Check if guests can create a new usergroup (create permission) Create a new usergroup row Associate the user to the usergroup (refer permission) This means that every user has his own dedicated user group by default. Signup API Link Sign up action can be allowed to guests to allow open registration by anyone. Users with enough permission over the user_account table can create users manually. Users registered using signup action are their own owners. Hence they can update and delete themselves. These permission can be changed based on the use case. POST call for user registration curl 'http://localhost:6336/action/user_account/signup' \\ -H 'Authorization: Bearer null' \\ -H 'Content-Type: application/json;charset=UTF-8' \\ -H 'Accept: application/json, text/plain, */*' \\ --data-binary '{\"attributes\":{\"name\":\"username\",\"email\":\"<UserEmail>\",\"password\":\"<Password>\",\"passwordConfirm\":\"<Password>\"}}' You can either allow guests to be able to invoke sign up action or allow only a particular user to be able to create new users or a usergroup. [ { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Created user\" , \"title\" : \"Success\" , \"type\" : \"success\" } } ] This user can sign in now (generate an auth token). But what he can access is again based on the permission of the system. Signup CURL example Link Creating a user manually curl '/api/user_account' \\ -H 'Authorization: Bearer <Auth Token>' \\ --data-binary '{ \"data\": { \"type\": \"user_account\", \"attributes\": { \"email\": \"test@user.com\", \"name\": \"test\", \"password\": \"password\", } } }' Sign In Link Sign In is also an action on user entity. Sign in takes two inputs: Email Password When the user initiates Sign in action, the following things happen: Check if guests can peek users table (Peek permission) Check if guests can peek the particular user (Peek Permission) Match if the provided password bcrypted matches the stored bcrypted password If true, issue a JWT token, which is used for future calls The main outcome of the Sign In action is the jwt token, which is to be used in the Authorization header of following calls. Sign in CURL example Link POST call for sign in curl 'http://localhost:6336/action/user_account/signin' \\ -H 'Content-Type: application/json;charset=UTF-8' \\ -H 'Accept: application/json, text/plain, */*' \\ --data-binary '{\"attributes\":{\"email\":\"<Email>\",\"password\":\"<Password>\"}}' [ { \"ResponseType\" : \"client.store.set\" , \"Attributes\" : { \"key\" : \"token\" , \"value\" : \"<AccessToken>\" } }, { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Logged in\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.redirect\" , \"Attributes\" : { \"delay\" : 2000 , \"location\" : \"/\" , \"window\" : \"self\" } } ] Directly into user_account table Link import requests headers = { 'Authorization' : 'Bearer <Auth Token>' , } data = '{ \"data\" : { \"type\" : \"user\" , \"attributes\" : { \"email\" : \"test@user.com\" , \"name\" : \"test\" , \"password\" : \"password\" , } } } ' response = requests . post ( 'http://localhost:6336/api/user' , headers = headers , data = data ) You can manually add users from the users page, or allow sign-up action to be performed by guests which will take care of creating a user and an associated usergroup for that user. All new signed up users will also be added to the \"users\" usergroup. Guests Link Requests without a valid Authorization Bearer token will be referred to as \"guests requests\". Requests with a valid token will have an identified user in the context. Authorization Link Daptin has a built-in authorization framework based on users groups and permissions. Users are identified by their authorization token or other means of identification. Each request is identified as coming from a registered user or a guest. Permission model Link Every read/write to the system passes through two level of permission check. Type level: apply permission on all types of entities at the same time Data level: object level permission The world table contains two columns: Permission : defines the entity level permission Default permission : defines the default permission for a new object of this entity type The default permission for an object is picked from the default permission setting, and can be changed after the object creation (if the permission allows). Peek Link Peek gives access to the user to read data in the system but not allow it in response as data. So while the query to read the data will execute and certain actions can be allowed over them, directly trying to read the data in response will fail. [C] Create Link Create allows a new row to be created by using the POST api. Note: this doesn't apply over indirect creations using actions *. [R] Read Link Read allows the data to be served in the http response body. The response will usually follow the JSONAPI.org structure. [U] Update Link Update allows the data fields to be updated using the PUT/PATCH http methods. [D] Delete Link Delete gives permission to be delete a row or certain type of data using DELETE http method. Unless you have enabled auditing , you will permanently loose this data. [R] Refer Link Refer gives permission to add data/users to usergroups. Note that you will also need certain permission on the usergroup as well. [X] Execute Link Execute gives permission to invoke action over data (like export). Note that giving access to a type of data doesn't give access to all rows of that entity type . Authorization Link Authorization is the part where daptin decides if the caller has enough permission to execute the call. Access check happens at two levels: Entity level check Object level check Both the checks have a \"before\" and \"after\" part. Object level permission check Link Once the call clears the entity level check, an object level permission check is applied. This happens in cases where the action is going to affect/read an existing row. The permission is stored in the same way. Each table has a permission column which stores the permission in OOOGGGXXX format. Order of permission check Link The permission is checked in order of: Check if the user is owner, if yes, check if permission allows the current action, if yes do action Check if the user belongs to a group to which this object also belongs, if yes, check if permisison allows the current action, if yes do action User is guest, check if guest permission allows this actions, if yes do action, if no, unauthorized Things to note here: There is no negative permission (this may be introduced in the future) eg, you cannot say owner is 'not allowed' to read but read by guest is allowed. Permission check is done in a hierarchy type order Access flow Link Every \"interaction\" in daptin goes through two levels of access. Each level has a before and after check. Entity level access: does the user invoking the interaction has the appropriate permission to invoke this (So for sign up, the user table need to be writable by guests, for sign in the user table needs to be peakable by guests) Instance level access: this is the second level, even if a User Account has access to \"user\" entity, not all \"user\" rows would be accessible by them So the actual checks happen in following order: \"Before check\" for entity \"Before check\" for instance \"After check\" for instance \"After check\" for entity Each of these checks can filter out objects where the user does not have enough permission. Entity level permission Link Entity level permission are set in the world table and can be updated from dashboard. This can be done by updating the \"permission\" column for the entity. For these changes to take effect a restart is necessary. Instance level permission Link Like we saw in the entity documentation , every table has a permission column. No restart is necessary for changes in these permission. You can choose to disable new user registration by changing the signup action permissions. User data API Examples Link Users are just like any other data you maintain. User information is stored in the user_account table and exposed over /api/user_account endpoint. You can choose to allow read/write permission directly to that table to allow other users/processes to use this api to read/create/update/delete users. User groups Link User groups is a group concept that helps you manage \"who\" can interact with daptin, and in what ways. All objects (including users and groups) belong to one or more user group. Users can interact with objects which also belong to their group based on the defined group permission setting Social login Link Oauth connection can be used to allow guests to identify themselves based on the email provided by the oauth id provider. Social login Link Allow users to login using their existing social accounts like twitter/google/github. Daptin can work with any oauth flow aware identity provider to allow new users to be registered (if you have disabled normal signup). Create a OAuth Connection and mark \"Allow login\" to enable APIs for OAuth flow. Examples Google login configuration Dropbox login configuration Github login configuration Linkedin login configuration Encrypted values The secrets are stored after encryption so the value you see in above screenshots are encrypted values. Configuring default user group Link You can configure which User groups should newly registered users be added to after their signup. This can be configured in the table properties from the dashboard or by updating the entity configuration from the API Restart required Restart is required for default group settings to take effect Authentication token Link The authentication token is a JWT token issued by daptin on sign in action. Users can create new actions to allow other means of generating JWT token. It is as simple as adding another outcome to an action. Server side Link Daptin uses OAuth 2 based authentication strategy. HTTP calls are checked for Authorization header, and if present, validated as a JWT token. The JWT token should have been issued by daptin earlier and should not have expired. To see how to generate JWT token, checkout the sing-in action . The JWT token contains the issuer information (daptin) plus basic user profile (email). The JWT token has a one hour (configurable) expiry from the time of issue. If the token is absent or invalid, the user is considered as a guest. Guests also have certain permissions. Checkout the Authorization docs for details. Client side Link On the client side, for dashboard, the token is stored in local storage. The local storage is cleared on logout or if the server responds with a 401 Unauthorized status.","title":"User management"},{"location":"setting-up/access/#user-management","text":"Daptin maintains its own User accounts and User groups entries in the database. Users are identified by email which is a unique key in the user_account entity. Passwords are stored using bcrypt with a cost of 11. Password field has a column_type password which makes daptin to bcrypt it before storing, and password fields are never returned in any JSONAPI call.","title":"User management"},{"location":"setting-up/access/#authentication","text":"Authentication involves identifying the current user of the request. Daptin expectes a JWT token issued at signin as Authorization: Bearer <Token> header, otherwise the request is considered coming from a guest .","title":"Authentication"},{"location":"setting-up/access/#sign-up","text":"Sign up is an action on user entity. Sign up takes four inputs: Name Email Password PasswordConfirm When the user initiates a Sign up action, the following things happen Check if guests can initiate sign in action Check if guests can create a new user (create permission) Create a new user row Check if guests can create a new usergroup (create permission) Create a new usergroup row Associate the user to the usergroup (refer permission) This means that every user has his own dedicated user group by default.","title":"Sign Up"},{"location":"setting-up/access/#signup-api","text":"Sign up action can be allowed to guests to allow open registration by anyone. Users with enough permission over the user_account table can create users manually. Users registered using signup action are their own owners. Hence they can update and delete themselves. These permission can be changed based on the use case. POST call for user registration curl 'http://localhost:6336/action/user_account/signup' \\ -H 'Authorization: Bearer null' \\ -H 'Content-Type: application/json;charset=UTF-8' \\ -H 'Accept: application/json, text/plain, */*' \\ --data-binary '{\"attributes\":{\"name\":\"username\",\"email\":\"<UserEmail>\",\"password\":\"<Password>\",\"passwordConfirm\":\"<Password>\"}}' You can either allow guests to be able to invoke sign up action or allow only a particular user to be able to create new users or a usergroup. [ { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Created user\" , \"title\" : \"Success\" , \"type\" : \"success\" } } ] This user can sign in now (generate an auth token). But what he can access is again based on the permission of the system.","title":"Signup API"},{"location":"setting-up/access/#signup-curl-example","text":"Creating a user manually curl '/api/user_account' \\ -H 'Authorization: Bearer <Auth Token>' \\ --data-binary '{ \"data\": { \"type\": \"user_account\", \"attributes\": { \"email\": \"test@user.com\", \"name\": \"test\", \"password\": \"password\", } } }'","title":"Signup CURL example"},{"location":"setting-up/access/#sign-in","text":"Sign In is also an action on user entity. Sign in takes two inputs: Email Password When the user initiates Sign in action, the following things happen: Check if guests can peek users table (Peek permission) Check if guests can peek the particular user (Peek Permission) Match if the provided password bcrypted matches the stored bcrypted password If true, issue a JWT token, which is used for future calls The main outcome of the Sign In action is the jwt token, which is to be used in the Authorization header of following calls.","title":"Sign In"},{"location":"setting-up/access/#sign-in-curl-example","text":"POST call for sign in curl 'http://localhost:6336/action/user_account/signin' \\ -H 'Content-Type: application/json;charset=UTF-8' \\ -H 'Accept: application/json, text/plain, */*' \\ --data-binary '{\"attributes\":{\"email\":\"<Email>\",\"password\":\"<Password>\"}}' [ { \"ResponseType\" : \"client.store.set\" , \"Attributes\" : { \"key\" : \"token\" , \"value\" : \"<AccessToken>\" } }, { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Logged in\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.redirect\" , \"Attributes\" : { \"delay\" : 2000 , \"location\" : \"/\" , \"window\" : \"self\" } } ]","title":"Sign in CURL example"},{"location":"setting-up/access/#directly-into-user_account-table","text":"import requests headers = { 'Authorization' : 'Bearer <Auth Token>' , } data = '{ \"data\" : { \"type\" : \"user\" , \"attributes\" : { \"email\" : \"test@user.com\" , \"name\" : \"test\" , \"password\" : \"password\" , } } } ' response = requests . post ( 'http://localhost:6336/api/user' , headers = headers , data = data ) You can manually add users from the users page, or allow sign-up action to be performed by guests which will take care of creating a user and an associated usergroup for that user. All new signed up users will also be added to the \"users\" usergroup.","title":"Directly into user_account table"},{"location":"setting-up/access/#guests","text":"Requests without a valid Authorization Bearer token will be referred to as \"guests requests\". Requests with a valid token will have an identified user in the context.","title":"Guests"},{"location":"setting-up/access/#authorization","text":"Daptin has a built-in authorization framework based on users groups and permissions. Users are identified by their authorization token or other means of identification. Each request is identified as coming from a registered user or a guest.","title":"Authorization"},{"location":"setting-up/access/#permission-model","text":"Every read/write to the system passes through two level of permission check. Type level: apply permission on all types of entities at the same time Data level: object level permission The world table contains two columns: Permission : defines the entity level permission Default permission : defines the default permission for a new object of this entity type The default permission for an object is picked from the default permission setting, and can be changed after the object creation (if the permission allows).","title":"Permission model"},{"location":"setting-up/access/#peek","text":"Peek gives access to the user to read data in the system but not allow it in response as data. So while the query to read the data will execute and certain actions can be allowed over them, directly trying to read the data in response will fail.","title":"Peek"},{"location":"setting-up/access/#c-create","text":"Create allows a new row to be created by using the POST api. Note: this doesn't apply over indirect creations using actions *.","title":"[C] Create"},{"location":"setting-up/access/#r-read","text":"Read allows the data to be served in the http response body. The response will usually follow the JSONAPI.org structure.","title":"[R] Read"},{"location":"setting-up/access/#u-update","text":"Update allows the data fields to be updated using the PUT/PATCH http methods.","title":"[U] Update"},{"location":"setting-up/access/#d-delete","text":"Delete gives permission to be delete a row or certain type of data using DELETE http method. Unless you have enabled auditing , you will permanently loose this data.","title":"[D] Delete"},{"location":"setting-up/access/#r-refer","text":"Refer gives permission to add data/users to usergroups. Note that you will also need certain permission on the usergroup as well.","title":"[R] Refer"},{"location":"setting-up/access/#x-execute","text":"Execute gives permission to invoke action over data (like export). Note that giving access to a type of data doesn't give access to all rows of that entity type .","title":"[X] Execute"},{"location":"setting-up/access/#authorization_1","text":"Authorization is the part where daptin decides if the caller has enough permission to execute the call. Access check happens at two levels: Entity level check Object level check Both the checks have a \"before\" and \"after\" part.","title":"Authorization"},{"location":"setting-up/access/#object-level-permission-check","text":"Once the call clears the entity level check, an object level permission check is applied. This happens in cases where the action is going to affect/read an existing row. The permission is stored in the same way. Each table has a permission column which stores the permission in OOOGGGXXX format.","title":"Object level permission check"},{"location":"setting-up/access/#order-of-permission-check","text":"The permission is checked in order of: Check if the user is owner, if yes, check if permission allows the current action, if yes do action Check if the user belongs to a group to which this object also belongs, if yes, check if permisison allows the current action, if yes do action User is guest, check if guest permission allows this actions, if yes do action, if no, unauthorized Things to note here: There is no negative permission (this may be introduced in the future) eg, you cannot say owner is 'not allowed' to read but read by guest is allowed. Permission check is done in a hierarchy type order","title":"Order of permission check"},{"location":"setting-up/access/#access-flow","text":"Every \"interaction\" in daptin goes through two levels of access. Each level has a before and after check. Entity level access: does the user invoking the interaction has the appropriate permission to invoke this (So for sign up, the user table need to be writable by guests, for sign in the user table needs to be peakable by guests) Instance level access: this is the second level, even if a User Account has access to \"user\" entity, not all \"user\" rows would be accessible by them So the actual checks happen in following order: \"Before check\" for entity \"Before check\" for instance \"After check\" for instance \"After check\" for entity Each of these checks can filter out objects where the user does not have enough permission.","title":"Access flow"},{"location":"setting-up/access/#entity-level-permission","text":"Entity level permission are set in the world table and can be updated from dashboard. This can be done by updating the \"permission\" column for the entity. For these changes to take effect a restart is necessary.","title":"Entity level permission"},{"location":"setting-up/access/#instance-level-permission","text":"Like we saw in the entity documentation , every table has a permission column. No restart is necessary for changes in these permission. You can choose to disable new user registration by changing the signup action permissions.","title":"Instance level permission"},{"location":"setting-up/access/#user-data-api-examples","text":"Users are just like any other data you maintain. User information is stored in the user_account table and exposed over /api/user_account endpoint. You can choose to allow read/write permission directly to that table to allow other users/processes to use this api to read/create/update/delete users.","title":"User data API Examples"},{"location":"setting-up/access/#user-groups","text":"User groups is a group concept that helps you manage \"who\" can interact with daptin, and in what ways. All objects (including users and groups) belong to one or more user group. Users can interact with objects which also belong to their group based on the defined group permission setting","title":"User groups"},{"location":"setting-up/access/#social-login","text":"Oauth connection can be used to allow guests to identify themselves based on the email provided by the oauth id provider.","title":"Social login"},{"location":"setting-up/access/#social-login_1","text":"Allow users to login using their existing social accounts like twitter/google/github. Daptin can work with any oauth flow aware identity provider to allow new users to be registered (if you have disabled normal signup). Create a OAuth Connection and mark \"Allow login\" to enable APIs for OAuth flow. Examples Google login configuration Dropbox login configuration Github login configuration Linkedin login configuration Encrypted values The secrets are stored after encryption so the value you see in above screenshots are encrypted values.","title":"Social login"},{"location":"setting-up/access/#configuring-default-user-group","text":"You can configure which User groups should newly registered users be added to after their signup. This can be configured in the table properties from the dashboard or by updating the entity configuration from the API Restart required Restart is required for default group settings to take effect","title":"Configuring default user group"},{"location":"setting-up/access/#authentication-token","text":"The authentication token is a JWT token issued by daptin on sign in action. Users can create new actions to allow other means of generating JWT token. It is as simple as adding another outcome to an action.","title":"Authentication token"},{"location":"setting-up/access/#server-side","text":"Daptin uses OAuth 2 based authentication strategy. HTTP calls are checked for Authorization header, and if present, validated as a JWT token. The JWT token should have been issued by daptin earlier and should not have expired. To see how to generate JWT token, checkout the sing-in action . The JWT token contains the issuer information (daptin) plus basic user profile (email). The JWT token has a one hour (configurable) expiry from the time of issue. If the token is absent or invalid, the user is considered as a guest. Guests also have certain permissions. Checkout the Authorization docs for details.","title":"Server side"},{"location":"setting-up/access/#client-side","text":"On the client side, for dashboard, the token is stored in local storage. The local storage is cleared on logout or if the server responds with a 401 Unauthorized status.","title":"Client side"},{"location":"setting-up/data_import/","text":"XLSX Link Try to have a one table per sheet kind of xlsx to upload. Upload from dashboard -- Todo add API call exmple here CSV Link JSON Link Take a JSON dump from the dashboard and note its format.","title":"XLSX"},{"location":"setting-up/data_import/#xlsx","text":"Try to have a one table per sheet kind of xlsx to upload. Upload from dashboard -- Todo add API call exmple here","title":"XLSX"},{"location":"setting-up/data_import/#csv","text":"","title":"CSV"},{"location":"setting-up/data_import/#json","text":"Take a JSON dump from the dashboard and note its format.","title":"JSON"},{"location":"setting-up/data_modeling/","text":"Data model Link Tables are the basic data structure. Tables have columns. Each column has a particular data type. Tables are exposed as JSON APIs under the /api/<entityName> path. Automatic creation Link Import CSV or XLS file and you can let Daptin create the entities for you based on intelligent data pre-processor. Manual creation Link YAML/JSON schema Link If you are looking for a more reproducible way, design your entities and create JSON or YAML files. These files can be used again to create an exact same replica. Multiple schema json files can be uploaded, and changes are merged accordingly. Lets imagine we were creating a todo application and wanted to keep a track of the following for each todo item Todo list example the todo text field - title YAML example Tables : - TableName : todo Columns : - Name : title DataType : varchar(500) ColumnType : label IsIndexed : true JSON example { \"Tables\" : [ { \"TableName\" : \"todo\" , \"Columns\" : [ { \"Name\" : \"title\" , \"DataType\" : \"varchar(500)\" , \"ColumnType\" : \"label\" , \"IsIndexed\" : true } ] } ] } Data validations Link Along with the fields mentioned above, we might want certain validations and conformations whenever we store a new todo Validations title cannot be empty order has to be numeric Once we have come up with the above picture in mind, we can use one of the following ways to tell daptin about this. Daptin uses the excellent go-playground/validator library to provide extensive validations when creating and updating data. It gives us the following unique features: Cross Field and Cross Struct validations by using validation tags or custom validators. Slice, Array and Map diving, which allows any or all levels of a multidimensional field to be validated. Validation Example Link JSON example Link JSON files are the primary way to create new entities in daptin. The above two ways ultimately create a JSON file or fetch from the market. The JSON for our todo entity will look as follows: { \"Tables\" : [{ \"TableName\" : \"todo\" , \"Columns\" : [{ \"Name\" : \"title\" , \"DataType\" : \"varchar(500)\" , \"ColumnType\" : \"label\" , \"IsIndexed\" : true }, { \"Name\" : \"completed\" , \"DataType\" : \"int(1)\" , \"ColumnType\" : \"truefalse\" , \"DefaultValue\" : \"false\" }, { \"Name\" : \"deadline\" , \"DataType\" : \"date\" , \"ColumnType\" : \"date\" , \"IsNullable\" : true }, { \"Name\" : \"order\" , \"ColumnName\" : \"item_order\" , \"DataType\" : \"int(4)\" , \"ColumnType\" : \"measurement\" , \"DefaultValue\" : \"10\" }, { \"Name\" : \"text\" , \"DataType\" : \"text\" , \"ColumnType\" : \"content\" , \"IsNullable\" : true } ], \"Conformations\" : [{ \"ColumnName\" : \"order\" , \"Tags\" : \"numeric\" }], \"validations\" : [{ \"ColumnName\" : \"title\" , \"Tags\" : \"required\" }] ] } Name: Name is a human readable name Column Name: Name of the column in the table Column Type: The type of the column. Daptin supports a variety of types and these allow daptin to give you useful options in future (eg for viewing a timeline, a date/datetime column is required) Default value: Columns can have default values, which is used a new row is created and no value for that column is specified. YAML example Link YAML example for todo entity is as follows Tables : - TableName : todo Columns : - Name : title DataType : varchar(500) ColumnType : label IsIndexed : true - Name : url DataType : varchar(200) ColumnType : url IsNullable : true - Name : completed DataType : int(1) ColumnType : truefalse DefaultValue : 'false' - Name : schedule DataType : date ColumnType : date IsNullable : true - Name : order ColumnName : item_order DataType : int(4) ColumnType : measurement DefaultValue : '10' - Name : text DataType : text ColumnType : content IsNullable : true Conformations : - ColumnName : order Tags : numeric Validations : - ColumnName : title Tags : required You can choose to work with either json or yaml. Once the schema is ready, it can be uploaded directly from daptin dashboard. Online entity designer Link The entity designer is accessible from dashboard using the \"Online designer\" button. Here you can set the name, add columns and relations and create it. This is a basic designer and more advanced features to customise every aspect of the entity will be added later. Column specifications Link Columns of the entity can be customized: Property Name Property Type Description Name string human readable name, can be skipped ColumnName string column name in the table ColumnDescription string human readable description ColumnType string column type is a rich type of the column IsIndexed boolean true to add an index on this column IsUnique boolean true to set a unique constraint on this column IsNullable boolean are null values allowed Permission uint64 permission column (check authorization docs) DataType string the column type inside the database DefaultValue string default value if any (has to be inside single quotes for static values Options Array[value,label] Valid values if column in enum type Column types Link Daptin supports a variety of rich data types, which helps it to automatically make intelligent decisions and validations. Here is a list of all column types and what should they be used for Type Name Description Example id an identity column, mostly for internal purposes 1 alias a foreign key column uuid v4 date full date, no time 2017-12-30 time time/time interval, no date 12:34:54 day day of the month 1 to 31 month month of the year 1 to 12 year Year 2017 minute minute of the hour 0 to 59 hour hour of the dat 0 - 23 datetime date + time (not stored as timestamp, served at date time string) 2017-12-30T12:34:54 email email test@domain.com name column to be used as name of the entity daptin json JSON data {} password password - are bcrypted with cost 11 $2a$11$z/VlxycDgZ... value value is enumeration type completed truefalse boolean 1 timestamp timestamp (stored as timestamp, served as timestamp) 123123123 location.latitude only latitude 34.2938 location latitude + longitude in geoJson format [34.223,64.123] location.longitude only longitude 64.123 location.altitude only altitude 34 color hex color string #ABCDE1 rating.10 rating on a scale of 10 8 measurement numeric column 534 label a label for the entity, similar to name but can be more than one red content larger contents - texts/html/json/yaml very long text file uploads, connect storage for using this url Urls/links http://docs.dapt.in Data relations Link A data oriented system with no relational knowledge of the data is next to an Excel sheet. Specifying relations in your data is the most important thing after creating your entities. Relations are constraints among tables and help you keep clean and consistent data. Relational data is easily accessible over APIs using a path structure like /api/<entityName>/<id>/<relationName> and the response is consistent with JSONAPI.org . Checkout the relation apis exposed by daptin. YAML example Relations : - Subject : todo Relation : has_one Object : project JSON example { \"Relations\" : [ { \"Subject\" : \"todo\" , \"Relation\" : \"has_one\" , \"Object\" : \"project\" } ] } Relations in JSON/YAML schema Link When uploading schema using a JSON / YAML file, relations can be added in the same file and daptin will create appropriate constraints and foreign keys in your underlying database. Continuing with our example of todos, lets say we want to group todo's in \"projects\" and each todo can belong to only a single project. Lets design a \"project\" entity: - TableName : project Columns : - Name : name DataType : varchar(200) ColumnType : name IsIndexed : true A very simple table with just a name column. Now we can tell daptin about the relation between todos and projects Relations : - Subject : todo Relation : has_one Object : project This tells daptin that todo \"has_one\" project. Relations types Link Any entity can be associated to any other entity (or to itself) as one of the follows Relation Name Relation Descriptio Can be empty belongs_to a single object relation No has_one a single object relation Yes has_many many related objects Yes Default relations Link Every entity created on daptin has at least two relations Relation Type Related Entity Purpose belongs user owner of the object has many usergroup belongs to usergroup These relations help you precisely control the authorization for each user. Read more about authorization and permissions Multiple relation Link There can be a scenario where two entities are related in more then 1 way. Consider the following example A blog entity A post entity Blog has many posts Each blog can have a \"highlighted post\" (blog has one \"highlighted post\") To achieve the above scenario, our schema would look like as follows Tables : - TableName : blog Columns : - Name : title DataType : varchar(500) ColumnType : label - Name : view_count DataType : int(11) ColumnType : measurement - TableName : post Columns : - Name : title DataType : varchar(200) ColumnType : label - Name : body DataType : text ColumnType : content - TableName : comment Columns : - Name : body DataType : text ColumnType : content - Name : likes_count ColumnName : likes_count DataType : int(11) ColumnType : measurement Relations : - Subject : comment Relation : belongs_to Object : post - Subject : post Relation : belongs_to Object : blog // this is our post belongs to blog relation - Subject : blog Relation : has_one Object : post ObjectName : current_post SubjectName : current_post_of // this is our highlighted post relation Notice the \"SubjectName\" and \"ObjectName\" keys which helps to name our relations more intuitively. SQL constraints Link belongs to Link A column is added to the subject entity, which refers to the Object entity, set to non nullable has one Link Same as above, but nullable has many Link A join table is created Importing data Link Upload one of these files: File Usage Schema JSON Create schema and apis CSV Auto create entity and upload data XLSX Auto create entity and upload data Data JSON Upload data from dumps Excel file upload Link Excel upload provides an easy way to create entities. This takes away the complexity of writing each column type. Daptin uses a combination of rules to identify columns and their types based on the data in the excel. You can upload data from XLS. Daptin will take care of going through your XLS file and identifying column types. This is one of the easiest and fastest ways to create entities and uploading data in daptin. You can specify relations among entities later from the online designer. CSV file upload Link CSV upload provides an easy way to create entities. This takes away the complexity of writing each column type. Daptin uses a combination of rules to identify columns and their types based on the data in the csv. You can upload data from CSV. Daptin will take care of going through your XLS file and identifying column types. This is one of the easiest and fastest ways to create entities and uploading data in daptin. You can specify relations among entities later from the online designer. Data conformations Link Daptin uses the excellent leebenson/conform library to apply conformations on data before storing them in the database Conform: keep user input in check (go, golang) Trim, sanitize, and modify struct string fields in place, based on tags. Use it for names, e-mail addresses, URL slugs, or any other form field where formatting matters. Conform doesn't attempt any kind of validation on your fields. Data auditing Link To enable recoding of all historical data for a particular entity, enable data audit for it in the worlds configuration. Audits are ready only and cannot be manipulated over api. You can configure the permission for your use case. All changes in daptin can be recorded by enabling auditing . History is maintained in separate audit tables which maintain a copy of all columns at each change. Audit table are entities just like regular entities. All Patch/Put/Delete calls to daptin will create an entry in the audit table if the entity is changed. Audit tables Link For any entity named <X> , another tables <X>_audit is added by daptin. Eg if you enable auditing of the user_account table, then a user_account_audit table will be created. The audit table will contain all the columns which are present in the original table, plus an extra column is_audit_of is added, which contains the ID of the original row. The is_audit_of is a foreign key column to the parent tables id column. Audit row Link Each row in the audit table is the copy of the original row just before it is being modified. The audit rows can be accessed just like any other relation. Audit table permissions Link By default, everyone has the access to create audit row, and no one has the access to update or delete them. These permissions can be changed, but it is not recommended at present. Type Permission Audit table permission 007007007 Audit object permission 003003003","title":"Data model"},{"location":"setting-up/data_modeling/#data-model","text":"Tables are the basic data structure. Tables have columns. Each column has a particular data type. Tables are exposed as JSON APIs under the /api/<entityName> path.","title":"Data model"},{"location":"setting-up/data_modeling/#automatic-creation","text":"Import CSV or XLS file and you can let Daptin create the entities for you based on intelligent data pre-processor.","title":"Automatic creation"},{"location":"setting-up/data_modeling/#manual-creation","text":"","title":"Manual creation"},{"location":"setting-up/data_modeling/#yamljson-schema","text":"If you are looking for a more reproducible way, design your entities and create JSON or YAML files. These files can be used again to create an exact same replica. Multiple schema json files can be uploaded, and changes are merged accordingly. Lets imagine we were creating a todo application and wanted to keep a track of the following for each todo item Todo list example the todo text field - title YAML example Tables : - TableName : todo Columns : - Name : title DataType : varchar(500) ColumnType : label IsIndexed : true JSON example { \"Tables\" : [ { \"TableName\" : \"todo\" , \"Columns\" : [ { \"Name\" : \"title\" , \"DataType\" : \"varchar(500)\" , \"ColumnType\" : \"label\" , \"IsIndexed\" : true } ] } ] }","title":"YAML/JSON schema"},{"location":"setting-up/data_modeling/#data-validations","text":"Along with the fields mentioned above, we might want certain validations and conformations whenever we store a new todo Validations title cannot be empty order has to be numeric Once we have come up with the above picture in mind, we can use one of the following ways to tell daptin about this. Daptin uses the excellent go-playground/validator library to provide extensive validations when creating and updating data. It gives us the following unique features: Cross Field and Cross Struct validations by using validation tags or custom validators. Slice, Array and Map diving, which allows any or all levels of a multidimensional field to be validated.","title":"Data validations"},{"location":"setting-up/data_modeling/#validation-example","text":"","title":"Validation Example"},{"location":"setting-up/data_modeling/#json-example","text":"JSON files are the primary way to create new entities in daptin. The above two ways ultimately create a JSON file or fetch from the market. The JSON for our todo entity will look as follows: { \"Tables\" : [{ \"TableName\" : \"todo\" , \"Columns\" : [{ \"Name\" : \"title\" , \"DataType\" : \"varchar(500)\" , \"ColumnType\" : \"label\" , \"IsIndexed\" : true }, { \"Name\" : \"completed\" , \"DataType\" : \"int(1)\" , \"ColumnType\" : \"truefalse\" , \"DefaultValue\" : \"false\" }, { \"Name\" : \"deadline\" , \"DataType\" : \"date\" , \"ColumnType\" : \"date\" , \"IsNullable\" : true }, { \"Name\" : \"order\" , \"ColumnName\" : \"item_order\" , \"DataType\" : \"int(4)\" , \"ColumnType\" : \"measurement\" , \"DefaultValue\" : \"10\" }, { \"Name\" : \"text\" , \"DataType\" : \"text\" , \"ColumnType\" : \"content\" , \"IsNullable\" : true } ], \"Conformations\" : [{ \"ColumnName\" : \"order\" , \"Tags\" : \"numeric\" }], \"validations\" : [{ \"ColumnName\" : \"title\" , \"Tags\" : \"required\" }] ] } Name: Name is a human readable name Column Name: Name of the column in the table Column Type: The type of the column. Daptin supports a variety of types and these allow daptin to give you useful options in future (eg for viewing a timeline, a date/datetime column is required) Default value: Columns can have default values, which is used a new row is created and no value for that column is specified.","title":"JSON example"},{"location":"setting-up/data_modeling/#yaml-example","text":"YAML example for todo entity is as follows Tables : - TableName : todo Columns : - Name : title DataType : varchar(500) ColumnType : label IsIndexed : true - Name : url DataType : varchar(200) ColumnType : url IsNullable : true - Name : completed DataType : int(1) ColumnType : truefalse DefaultValue : 'false' - Name : schedule DataType : date ColumnType : date IsNullable : true - Name : order ColumnName : item_order DataType : int(4) ColumnType : measurement DefaultValue : '10' - Name : text DataType : text ColumnType : content IsNullable : true Conformations : - ColumnName : order Tags : numeric Validations : - ColumnName : title Tags : required You can choose to work with either json or yaml. Once the schema is ready, it can be uploaded directly from daptin dashboard.","title":"YAML example"},{"location":"setting-up/data_modeling/#online-entity-designer","text":"The entity designer is accessible from dashboard using the \"Online designer\" button. Here you can set the name, add columns and relations and create it. This is a basic designer and more advanced features to customise every aspect of the entity will be added later.","title":"Online entity designer"},{"location":"setting-up/data_modeling/#column-specifications","text":"Columns of the entity can be customized: Property Name Property Type Description Name string human readable name, can be skipped ColumnName string column name in the table ColumnDescription string human readable description ColumnType string column type is a rich type of the column IsIndexed boolean true to add an index on this column IsUnique boolean true to set a unique constraint on this column IsNullable boolean are null values allowed Permission uint64 permission column (check authorization docs) DataType string the column type inside the database DefaultValue string default value if any (has to be inside single quotes for static values Options Array[value,label] Valid values if column in enum type","title":"Column specifications"},{"location":"setting-up/data_modeling/#column-types","text":"Daptin supports a variety of rich data types, which helps it to automatically make intelligent decisions and validations. Here is a list of all column types and what should they be used for Type Name Description Example id an identity column, mostly for internal purposes 1 alias a foreign key column uuid v4 date full date, no time 2017-12-30 time time/time interval, no date 12:34:54 day day of the month 1 to 31 month month of the year 1 to 12 year Year 2017 minute minute of the hour 0 to 59 hour hour of the dat 0 - 23 datetime date + time (not stored as timestamp, served at date time string) 2017-12-30T12:34:54 email email test@domain.com name column to be used as name of the entity daptin json JSON data {} password password - are bcrypted with cost 11 $2a$11$z/VlxycDgZ... value value is enumeration type completed truefalse boolean 1 timestamp timestamp (stored as timestamp, served as timestamp) 123123123 location.latitude only latitude 34.2938 location latitude + longitude in geoJson format [34.223,64.123] location.longitude only longitude 64.123 location.altitude only altitude 34 color hex color string #ABCDE1 rating.10 rating on a scale of 10 8 measurement numeric column 534 label a label for the entity, similar to name but can be more than one red content larger contents - texts/html/json/yaml very long text file uploads, connect storage for using this url Urls/links http://docs.dapt.in","title":"Column types"},{"location":"setting-up/data_modeling/#data-relations","text":"A data oriented system with no relational knowledge of the data is next to an Excel sheet. Specifying relations in your data is the most important thing after creating your entities. Relations are constraints among tables and help you keep clean and consistent data. Relational data is easily accessible over APIs using a path structure like /api/<entityName>/<id>/<relationName> and the response is consistent with JSONAPI.org . Checkout the relation apis exposed by daptin. YAML example Relations : - Subject : todo Relation : has_one Object : project JSON example { \"Relations\" : [ { \"Subject\" : \"todo\" , \"Relation\" : \"has_one\" , \"Object\" : \"project\" } ] }","title":"Data relations"},{"location":"setting-up/data_modeling/#relations-in-jsonyaml-schema","text":"When uploading schema using a JSON / YAML file, relations can be added in the same file and daptin will create appropriate constraints and foreign keys in your underlying database. Continuing with our example of todos, lets say we want to group todo's in \"projects\" and each todo can belong to only a single project. Lets design a \"project\" entity: - TableName : project Columns : - Name : name DataType : varchar(200) ColumnType : name IsIndexed : true A very simple table with just a name column. Now we can tell daptin about the relation between todos and projects Relations : - Subject : todo Relation : has_one Object : project This tells daptin that todo \"has_one\" project.","title":"Relations in JSON/YAML schema"},{"location":"setting-up/data_modeling/#relations-types","text":"Any entity can be associated to any other entity (or to itself) as one of the follows Relation Name Relation Descriptio Can be empty belongs_to a single object relation No has_one a single object relation Yes has_many many related objects Yes","title":"Relations types"},{"location":"setting-up/data_modeling/#default-relations","text":"Every entity created on daptin has at least two relations Relation Type Related Entity Purpose belongs user owner of the object has many usergroup belongs to usergroup These relations help you precisely control the authorization for each user. Read more about authorization and permissions","title":"Default relations"},{"location":"setting-up/data_modeling/#multiple-relation","text":"There can be a scenario where two entities are related in more then 1 way. Consider the following example A blog entity A post entity Blog has many posts Each blog can have a \"highlighted post\" (blog has one \"highlighted post\") To achieve the above scenario, our schema would look like as follows Tables : - TableName : blog Columns : - Name : title DataType : varchar(500) ColumnType : label - Name : view_count DataType : int(11) ColumnType : measurement - TableName : post Columns : - Name : title DataType : varchar(200) ColumnType : label - Name : body DataType : text ColumnType : content - TableName : comment Columns : - Name : body DataType : text ColumnType : content - Name : likes_count ColumnName : likes_count DataType : int(11) ColumnType : measurement Relations : - Subject : comment Relation : belongs_to Object : post - Subject : post Relation : belongs_to Object : blog // this is our post belongs to blog relation - Subject : blog Relation : has_one Object : post ObjectName : current_post SubjectName : current_post_of // this is our highlighted post relation Notice the \"SubjectName\" and \"ObjectName\" keys which helps to name our relations more intuitively.","title":"Multiple relation"},{"location":"setting-up/data_modeling/#sql-constraints","text":"","title":"SQL constraints"},{"location":"setting-up/data_modeling/#belongs-to","text":"A column is added to the subject entity, which refers to the Object entity, set to non nullable","title":"belongs to"},{"location":"setting-up/data_modeling/#has-one","text":"Same as above, but nullable","title":"has one"},{"location":"setting-up/data_modeling/#has-many","text":"A join table is created","title":"has many"},{"location":"setting-up/data_modeling/#importing-data","text":"Upload one of these files: File Usage Schema JSON Create schema and apis CSV Auto create entity and upload data XLSX Auto create entity and upload data Data JSON Upload data from dumps","title":"Importing data"},{"location":"setting-up/data_modeling/#excel-file-upload","text":"Excel upload provides an easy way to create entities. This takes away the complexity of writing each column type. Daptin uses a combination of rules to identify columns and their types based on the data in the excel. You can upload data from XLS. Daptin will take care of going through your XLS file and identifying column types. This is one of the easiest and fastest ways to create entities and uploading data in daptin. You can specify relations among entities later from the online designer.","title":"Excel file upload"},{"location":"setting-up/data_modeling/#csv-file-upload","text":"CSV upload provides an easy way to create entities. This takes away the complexity of writing each column type. Daptin uses a combination of rules to identify columns and their types based on the data in the csv. You can upload data from CSV. Daptin will take care of going through your XLS file and identifying column types. This is one of the easiest and fastest ways to create entities and uploading data in daptin. You can specify relations among entities later from the online designer.","title":"CSV file upload"},{"location":"setting-up/data_modeling/#data-conformations","text":"Daptin uses the excellent leebenson/conform library to apply conformations on data before storing them in the database Conform: keep user input in check (go, golang) Trim, sanitize, and modify struct string fields in place, based on tags. Use it for names, e-mail addresses, URL slugs, or any other form field where formatting matters. Conform doesn't attempt any kind of validation on your fields.","title":"Data conformations"},{"location":"setting-up/data_modeling/#data-auditing","text":"To enable recoding of all historical data for a particular entity, enable data audit for it in the worlds configuration. Audits are ready only and cannot be manipulated over api. You can configure the permission for your use case. All changes in daptin can be recorded by enabling auditing . History is maintained in separate audit tables which maintain a copy of all columns at each change. Audit table are entities just like regular entities. All Patch/Put/Delete calls to daptin will create an entry in the audit table if the entity is changed.","title":"Data auditing"},{"location":"setting-up/data_modeling/#audit-tables","text":"For any entity named <X> , another tables <X>_audit is added by daptin. Eg if you enable auditing of the user_account table, then a user_account_audit table will be created. The audit table will contain all the columns which are present in the original table, plus an extra column is_audit_of is added, which contains the ID of the original row. The is_audit_of is a foreign key column to the parent tables id column.","title":"Audit tables"},{"location":"setting-up/data_modeling/#audit-row","text":"Each row in the audit table is the copy of the original row just before it is being modified. The audit rows can be accessed just like any other relation.","title":"Audit row"},{"location":"setting-up/data_modeling/#audit-table-permissions","text":"By default, everyone has the access to create audit row, and no one has the access to update or delete them. These permissions can be changed, but it is not recommended at present. Type Permission Audit table permission 007007007 Audit object permission 003003003","title":"Audit table permissions"},{"location":"setting-up/enabling-features/","text":"_config table Link Entries: Setting Name Purpose hostname used for identification as IMAP/SMTP server jwt.secret used for signing the jwt tokens issue at login logs.enable enable/disable the /_logs endpoint which streams live logs encryption.secret secret used to encrypt data for storing in encrypted columns jwt.token.issuer issuer identifier in the jwt tokens rclone.retries number of default retries set for rclone related actions imap.enabled enable/disable IMAP endpoint jwt.token.life.hours the life time of tokens issued at login totp.secret TOTP secret used for CSRF token generation and 2factor token generator Get value _config table API Link curl \\ -H \"Authorization: Bearer <ADMIN_TOKEN>\" localhost:6336/_config/backend/<setting.name> Set new value _config table API Link curl \\ -H \"Authorization: Bearer <ADMIN_TOKEN>\" localhost:6336/_config/backend/<setting.name> \\ -- data \"New Value\"","title":"Enable/Disabling features"},{"location":"setting-up/enabling-features/#_config-table","text":"Entries: Setting Name Purpose hostname used for identification as IMAP/SMTP server jwt.secret used for signing the jwt tokens issue at login logs.enable enable/disable the /_logs endpoint which streams live logs encryption.secret secret used to encrypt data for storing in encrypted columns jwt.token.issuer issuer identifier in the jwt tokens rclone.retries number of default retries set for rclone related actions imap.enabled enable/disable IMAP endpoint jwt.token.life.hours the life time of tokens issued at login totp.secret TOTP secret used for CSRF token generation and 2factor token generator","title":"_config table"},{"location":"setting-up/enabling-features/#get-value-_config-table-api","text":"curl \\ -H \"Authorization: Bearer <ADMIN_TOKEN>\" localhost:6336/_config/backend/<setting.name>","title":"Get value _config table API"},{"location":"setting-up/enabling-features/#set-new-value-_config-table-api","text":"curl \\ -H \"Authorization: Bearer <ADMIN_TOKEN>\" localhost:6336/_config/backend/<setting.name> \\ -- data \"New Value\"","title":"Set new value _config table API"},{"location":"setting-up/installation/","text":"Installation Link Deploying a new instance Link Deployment preference Getting started Heroku Docker docker run -p 8080:8080 daptin/daptin Kubernetes Service & Deployment YAML Development go get github.com/daptin/daptin Linux (386/amd64/arm5,6,7) Download static linux builds Windows go get github.com/daptin/daptin OS X go get github.com/daptin/daptin Load testing Docker compose Raspberry Pi Linux arm 7 static build Native binary Link Daptin is available as a native binary. You can download the binary for the following os from github releases Windows 32/64 OS X 64 Linux 32/64/arm/mips https://github.com/daptin/daptin/releases Execute ./daptin to run daptin. It will create a sqlite database on the disk and start listening on port 6336. CLI Options: Link Argument Definition port set the port to listen http_port set the https port to listen runtime runtime test/debug/release for logs dashboard path to default dashboard static build served at [ / ] db_type mysql/postgres/sqlite3 db_connection_string Database Connection String Database connection string Link SQLite Link -db_connection_string test.db MySQL Link -db_connection_string \"<username>:<password>@tcp(<hostname>:<port>)/<db_name>\" POSTGRESql: Link -db_connection_string \"host=<hostname> port=<port> user=<username> password=<password> dbname=<db_name> sslmode=enable/disable\" Heroku deployment Link Heroku is the best way to test out a live instance of daptin. Daptin has a very low memory footprint and can run smoothly even on heroku's smallest instance. Note: Heroku puts instances to sleep after 30 minutes of idleness, which will erase all the data. It will behave like a fresh instance when it wakes up. You can subscribe to their minimum paid plan to remove this sleep due to idleness. Docker image Link Deploy the docker image Start daptin on your machine using docker docker run -p 8080:8080 daptin/daptin https://hub.docker.com/r/daptin/daptin/ Docker-compose Link Docker compose is a great tool to bring up a mysql/postgres backed daptin instance version : '3' services : web : image : daptin/daptin ports : - \"8090:8080\" restart : always environment : DAPTIN_PORT : '8080' DAPTIN_DB_TYPE : 'mysql' DAPTIN_DB_CONNECTION_STRING : 'dev:dev@tcp(mysqldb:3306)/daptin' depends_on : - mysqldb mysqldb : image : mysql container_name : ${MYSQL_HOST} restart : always env_file : - \".env\" environment : - MYSQL_DATABASE=${MYSQL_DATABASE} - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD} - MYSQL_USER=${MYSQL_USER} - MYSQL_PASSWORD=${MYSQL_PASSWORD} ports : - \"8989:3306\" volumes : - \"./data/db/mysql:/var/lib/mysql\" Kubernetes deployment Link Daptin can be infinitely scaled on kubernetes Example apiVersion : v1 kind : Service metadata : name : daptin-instance labels : app : daptin spec : ports : - port : 8080 selector : app : daptin tier : production --- apiVersion : extensions/v1beta1 kind : Deployment metadata : name : daptin-daptin labels : app : daptin spec : strategy : type : Recreate template : metadata : labels : app : daptin tier : testing spec : containers : - image : daptin/daptin:latest name : daptin args : [ '-db_type' , 'mysql' , '-db_connection_string' , 'user:password@tcp(<mysql_service>:3306)/daptin' ] ports : - containerPort : 8080 name : daptin --- apiVersion : extensions/v1beta1 kind : Ingress metadata : name : daptin-test spec : rules : - host : hello.website http : paths : - backend : serviceName : daptin-testing servicePort : 8080 Database configuration Link Daptin can use one of the following database for data persistence Mysql Postgres SQLite [Default] If nothing specified, a sqlite database is created on the local file system and is used for all purposes. (uploads/blobs are not stored in database) You can customise the database connection properties when starting daptin MySQL Link To use mysql, start daptin as follows ./daptin -db_type=mysql -db_connection_string='<username>:<password>@tcp(<hostname>:<port>)/<db_name>' PostgreSQL Link ./daptin -db_type=postgres -db_connection_string='host=<hostname> port=<port> user=<username> password=<password> dbname=<db_name> sslmode=enable/disable' SQLite Link By default a \"daptin.db\" file is created to store data ./daptin -db_type=sqlite -db_connection_string=db_file_name.db Port Link Daptin will use the following ports for various services (when enabled) -port :8080 Service Port To change HTTP (JSON/GraphQL) 6336 CLI option -port :80 HTTPS 6443 CLI option -https_port :80 IMAP 6443 _config entry SMTP 2525 /mail_server row entry Restart Link Various low level configure changes requires a reset of the server to take place. Restart can be triggered using an action API and takes about 5-10 seconds. You can issue a daptin restart from the dashboard. Daptin takes about 15 seconds approx to start up and configure everything.","title":"Installation"},{"location":"setting-up/installation/#installation","text":"","title":"Installation"},{"location":"setting-up/installation/#deploying-a-new-instance","text":"Deployment preference Getting started Heroku Docker docker run -p 8080:8080 daptin/daptin Kubernetes Service & Deployment YAML Development go get github.com/daptin/daptin Linux (386/amd64/arm5,6,7) Download static linux builds Windows go get github.com/daptin/daptin OS X go get github.com/daptin/daptin Load testing Docker compose Raspberry Pi Linux arm 7 static build","title":"Deploying a new instance"},{"location":"setting-up/installation/#native-binary","text":"Daptin is available as a native binary. You can download the binary for the following os from github releases Windows 32/64 OS X 64 Linux 32/64/arm/mips https://github.com/daptin/daptin/releases Execute ./daptin to run daptin. It will create a sqlite database on the disk and start listening on port 6336.","title":"Native binary"},{"location":"setting-up/installation/#cli-options","text":"Argument Definition port set the port to listen http_port set the https port to listen runtime runtime test/debug/release for logs dashboard path to default dashboard static build served at [ / ] db_type mysql/postgres/sqlite3 db_connection_string Database Connection String","title":"CLI Options:"},{"location":"setting-up/installation/#database-connection-string","text":"","title":"Database connection string"},{"location":"setting-up/installation/#sqlite","text":"-db_connection_string test.db","title":"SQLite"},{"location":"setting-up/installation/#mysql","text":"-db_connection_string \"<username>:<password>@tcp(<hostname>:<port>)/<db_name>\"","title":"MySQL"},{"location":"setting-up/installation/#postgresql","text":"-db_connection_string \"host=<hostname> port=<port> user=<username> password=<password> dbname=<db_name> sslmode=enable/disable\"","title":"POSTGRESql:"},{"location":"setting-up/installation/#heroku-deployment","text":"Heroku is the best way to test out a live instance of daptin. Daptin has a very low memory footprint and can run smoothly even on heroku's smallest instance. Note: Heroku puts instances to sleep after 30 minutes of idleness, which will erase all the data. It will behave like a fresh instance when it wakes up. You can subscribe to their minimum paid plan to remove this sleep due to idleness.","title":"Heroku deployment"},{"location":"setting-up/installation/#docker-image","text":"Deploy the docker image Start daptin on your machine using docker docker run -p 8080:8080 daptin/daptin https://hub.docker.com/r/daptin/daptin/","title":"Docker image"},{"location":"setting-up/installation/#docker-compose","text":"Docker compose is a great tool to bring up a mysql/postgres backed daptin instance version : '3' services : web : image : daptin/daptin ports : - \"8090:8080\" restart : always environment : DAPTIN_PORT : '8080' DAPTIN_DB_TYPE : 'mysql' DAPTIN_DB_CONNECTION_STRING : 'dev:dev@tcp(mysqldb:3306)/daptin' depends_on : - mysqldb mysqldb : image : mysql container_name : ${MYSQL_HOST} restart : always env_file : - \".env\" environment : - MYSQL_DATABASE=${MYSQL_DATABASE} - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD} - MYSQL_USER=${MYSQL_USER} - MYSQL_PASSWORD=${MYSQL_PASSWORD} ports : - \"8989:3306\" volumes : - \"./data/db/mysql:/var/lib/mysql\"","title":"Docker-compose"},{"location":"setting-up/installation/#kubernetes-deployment","text":"Daptin can be infinitely scaled on kubernetes Example apiVersion : v1 kind : Service metadata : name : daptin-instance labels : app : daptin spec : ports : - port : 8080 selector : app : daptin tier : production --- apiVersion : extensions/v1beta1 kind : Deployment metadata : name : daptin-daptin labels : app : daptin spec : strategy : type : Recreate template : metadata : labels : app : daptin tier : testing spec : containers : - image : daptin/daptin:latest name : daptin args : [ '-db_type' , 'mysql' , '-db_connection_string' , 'user:password@tcp(<mysql_service>:3306)/daptin' ] ports : - containerPort : 8080 name : daptin --- apiVersion : extensions/v1beta1 kind : Ingress metadata : name : daptin-test spec : rules : - host : hello.website http : paths : - backend : serviceName : daptin-testing servicePort : 8080","title":"Kubernetes deployment"},{"location":"setting-up/installation/#database-configuration","text":"Daptin can use one of the following database for data persistence Mysql Postgres SQLite [Default] If nothing specified, a sqlite database is created on the local file system and is used for all purposes. (uploads/blobs are not stored in database) You can customise the database connection properties when starting daptin","title":"Database configuration"},{"location":"setting-up/installation/#mysql_1","text":"To use mysql, start daptin as follows ./daptin -db_type=mysql -db_connection_string='<username>:<password>@tcp(<hostname>:<port>)/<db_name>'","title":"MySQL"},{"location":"setting-up/installation/#postgresql_1","text":"./daptin -db_type=postgres -db_connection_string='host=<hostname> port=<port> user=<username> password=<password> dbname=<db_name> sslmode=enable/disable'","title":"PostgreSQL"},{"location":"setting-up/installation/#sqlite_1","text":"By default a \"daptin.db\" file is created to store data ./daptin -db_type=sqlite -db_connection_string=db_file_name.db","title":"SQLite"},{"location":"setting-up/installation/#port","text":"Daptin will use the following ports for various services (when enabled) -port :8080 Service Port To change HTTP (JSON/GraphQL) 6336 CLI option -port :80 HTTPS 6443 CLI option -https_port :80 IMAP 6443 _config entry SMTP 2525 /mail_server row entry","title":"Port"},{"location":"setting-up/installation/#restart","text":"Various low level configure changes requires a reset of the server to take place. Restart can be triggered using an action API and takes about 5-10 seconds. You can issue a daptin restart from the dashboard. Daptin takes about 15 seconds approx to start up and configure everything.","title":"Restart"},{"location":"setting-up/native/","text":"","title":"Native"},{"location":"setting-up/settingup/","text":"Getting started Link Accessing web dashboard Link Open up the dashboard on http://localhost:8080/ You will be presented with the Sign-in screen. If you are on a freshly created instance, then you need to create a user first. First user Link Use the dashboard to sign-up as the first user or call the sign-up API manually to create the first user. API CALL As you will see later in actions sign up and sign in api's are nothing special but just actions defined on certain tables. Request curl 'http://localhost/action/user_account/signup' --data '{\"attributes\":{\"name\":\"name\",\"email\":\"email@domain.com\",\"password\":\"password123\",\"passwordConfirm\":\"password123\"}}' Response [{ \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Created user_account\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Created usergroup\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Created user_account_user_account_id_has_usergroup_usergroup_id\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"__type\" : \"client.notify\" , \"message\" : \"Sign-up successful. Redirecting to sign in\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.redirect\" , \"Attributes\" : { \"__type\" : \"client.redirect\" , \"delay\" : 2000 , \"location\" : \"/auth/signin\" , \"window\" : \"self\" } }] Nothing important in the response of signup to keep track of. Successful response means now we can login as a user and become the administrator. A failure response would look like this: [{ \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Failed to create user_account. Error 1062: Duplicate entry 'email@domain.com' for key 'i79f4e12e72442d30f2b99a84fce3c392'\" , \"title\" : \"Failed\" , \"type\" : \"error\" } }] Or [{ \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"http error (400) email and 0 more errors, invalid value for email\" , \"title\" : \"failed\" , \"type\" : \"error\" } }] Logging in dashboard Link API CAll Request curl 'http://localhost/action/user_account/signin' --data '{\"attributes\":{\"email\":\"email@domain.com\",\"password\":\"password123\"}}' Response [{ \"ResponseType\" : \"client.store.set\" , \"Attributes\" : { \"key\" : \"token\" , \"value\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFydHBhckBnbWFpbC5jb20iLCJleHAiOjE1ODE2MTcxNTEsImlhdCI6IjIwMjAtMDItMTBUMjM6MzU6NTEuMTc2MjA5ODAxKzA1OjMwIiwiaXNzIjoiZGFwdGluLTNhZTI5ZCIsImp0aSI6IjQ4MTRkYjhhLTg1ZWEtNDc0ZS1iMWQ0LWQ5OGM4MTU5ZDU5MCIsIm5hbWUiOiJwYXJ0aCIsIm5iZiI6MTU4MTM1Nzk1MSwicGljdHVyZSI6Imh0dHBzOi8vd3d3LmdyYXZhdGFyLmNvbS9hdmF0YXIvM2M5MjI3NmI4NmMzNGJkNjZmZjQwMzFlNjNmM2JkZTdcdTAwMjZkPW1vbnN0ZXJpZCJ9.deocIlHXWH_2fsrYBx5lSGQVJxad044tj4j4amy2Zyk\" } }, { \"ResponseType\" : \"client.cookie.set\" , \"Attributes\" : { \"key\" : \"token\" , \"value\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFydHBhckBnbWFpbC5jb20iLCJleHAiOjE1ODE2MTcxNTEsImlhdCI6IjIwMjAtMDItMTBUMjM6MzU6NTEuMTc2MjA5ODAxKzA1OjMwIiwiaXNzIjoiZGFwdGluLTNhZTI5ZCIsImp0aSI6IjQ4MTRkYjhhLTg1ZWEtNDc0ZS1iMWQ0LWQ5OGM4MTU5ZDU5MCIsIm5hbWUiOiJwYXJ0aCIsIm5iZiI6MTU4MTM1Nzk1MSwicGljdHVyZSI6Imh0dHBzOi8vd3d3LmdyYXZhdGFyLmNvbS9hdmF0YXIvM2M5MjI3NmI4NmMzNGJkNjZmZjQwMzFlNjNmM2JkZTdcdTAwMjZkPW1vbnN0ZXJpZCJ9.deocIlHXWH_2fsrYBx5lSGQVJxad044tj4j4amy2Zyk\" } }, { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Logged in\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.redirect\" , \"Attributes\" : { \"delay\" : 2000 , \"location\" : \"/\" , \"window\" : \"self\" } }] The token is to be used in the Authorization header of for all HTTP calls to identify the user. Become Administrator Link On the main screen of the dashboard under \"Users\" heading, locate the \"Become admin\" button. Clicking this will make the following changes: Disallow the sign-up API for guests Makes you the owner of all the data","title":"Getting started"},{"location":"setting-up/settingup/#getting-started","text":"","title":"Getting started"},{"location":"setting-up/settingup/#accessing-web-dashboard","text":"Open up the dashboard on http://localhost:8080/ You will be presented with the Sign-in screen. If you are on a freshly created instance, then you need to create a user first.","title":"Accessing web dashboard"},{"location":"setting-up/settingup/#first-user","text":"Use the dashboard to sign-up as the first user or call the sign-up API manually to create the first user. API CALL As you will see later in actions sign up and sign in api's are nothing special but just actions defined on certain tables. Request curl 'http://localhost/action/user_account/signup' --data '{\"attributes\":{\"name\":\"name\",\"email\":\"email@domain.com\",\"password\":\"password123\",\"passwordConfirm\":\"password123\"}}' Response [{ \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Created user_account\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Created usergroup\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Created user_account_user_account_id_has_usergroup_usergroup_id\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"__type\" : \"client.notify\" , \"message\" : \"Sign-up successful. Redirecting to sign in\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.redirect\" , \"Attributes\" : { \"__type\" : \"client.redirect\" , \"delay\" : 2000 , \"location\" : \"/auth/signin\" , \"window\" : \"self\" } }] Nothing important in the response of signup to keep track of. Successful response means now we can login as a user and become the administrator. A failure response would look like this: [{ \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Failed to create user_account. Error 1062: Duplicate entry 'email@domain.com' for key 'i79f4e12e72442d30f2b99a84fce3c392'\" , \"title\" : \"Failed\" , \"type\" : \"error\" } }] Or [{ \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"http error (400) email and 0 more errors, invalid value for email\" , \"title\" : \"failed\" , \"type\" : \"error\" } }]","title":"First user"},{"location":"setting-up/settingup/#logging-in-dashboard","text":"API CAll Request curl 'http://localhost/action/user_account/signin' --data '{\"attributes\":{\"email\":\"email@domain.com\",\"password\":\"password123\"}}' Response [{ \"ResponseType\" : \"client.store.set\" , \"Attributes\" : { \"key\" : \"token\" , \"value\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFydHBhckBnbWFpbC5jb20iLCJleHAiOjE1ODE2MTcxNTEsImlhdCI6IjIwMjAtMDItMTBUMjM6MzU6NTEuMTc2MjA5ODAxKzA1OjMwIiwiaXNzIjoiZGFwdGluLTNhZTI5ZCIsImp0aSI6IjQ4MTRkYjhhLTg1ZWEtNDc0ZS1iMWQ0LWQ5OGM4MTU5ZDU5MCIsIm5hbWUiOiJwYXJ0aCIsIm5iZiI6MTU4MTM1Nzk1MSwicGljdHVyZSI6Imh0dHBzOi8vd3d3LmdyYXZhdGFyLmNvbS9hdmF0YXIvM2M5MjI3NmI4NmMzNGJkNjZmZjQwMzFlNjNmM2JkZTdcdTAwMjZkPW1vbnN0ZXJpZCJ9.deocIlHXWH_2fsrYBx5lSGQVJxad044tj4j4amy2Zyk\" } }, { \"ResponseType\" : \"client.cookie.set\" , \"Attributes\" : { \"key\" : \"token\" , \"value\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFydHBhckBnbWFpbC5jb20iLCJleHAiOjE1ODE2MTcxNTEsImlhdCI6IjIwMjAtMDItMTBUMjM6MzU6NTEuMTc2MjA5ODAxKzA1OjMwIiwiaXNzIjoiZGFwdGluLTNhZTI5ZCIsImp0aSI6IjQ4MTRkYjhhLTg1ZWEtNDc0ZS1iMWQ0LWQ5OGM4MTU5ZDU5MCIsIm5hbWUiOiJwYXJ0aCIsIm5iZiI6MTU4MTM1Nzk1MSwicGljdHVyZSI6Imh0dHBzOi8vd3d3LmdyYXZhdGFyLmNvbS9hdmF0YXIvM2M5MjI3NmI4NmMzNGJkNjZmZjQwMzFlNjNmM2JkZTdcdTAwMjZkPW1vbnN0ZXJpZCJ9.deocIlHXWH_2fsrYBx5lSGQVJxad044tj4j4amy2Zyk\" } }, { \"ResponseType\" : \"client.notify\" , \"Attributes\" : { \"message\" : \"Logged in\" , \"title\" : \"Success\" , \"type\" : \"success\" } }, { \"ResponseType\" : \"client.redirect\" , \"Attributes\" : { \"delay\" : 2000 , \"location\" : \"/\" , \"window\" : \"self\" } }] The token is to be used in the Authorization header of for all HTTP calls to identify the user.","title":"Logging in dashboard"},{"location":"setting-up/settingup/#become-administrator","text":"On the main screen of the dashboard under \"Users\" heading, locate the \"Become admin\" button. Clicking this will make the following changes: Disallow the sign-up API for guests Makes you the owner of all the data","title":"Become Administrator"},{"location":"state/machines/","text":"State tracking Link State of an object can help you tracing any sort of progress while making sure you maintain the consistence of the state. For eg, you might want to track the status of a \"blog post\" in terms of \"draft\"/\"edited\"/\"published\" which pre-defined endpoints defining the flow of states. Tracking the status of things is one of the most common operation in most business flows. Daptin has a native support for state tracking and allows a lot of convienent features. Defining a state machine Link Define a state machine in YAML or JSON as follows: State machine description YAML StateMachineDescriptions : - Name : task_status Label : Task Status InitialState : to_be_done Events : - Name : start Label : Start Src : - to_be_done - delayed Dst : started - Name : delayed Label : Unable to pick up Src : - to_be_done Dst : delayed - Name : ongoing Label : Record progress Src : - started - ongoing Dst : ongoing - Name : interrupted Label : Interrupted Src : - started - ongoing Dst : interrupted - Name : resume Label : Resume from interruption Src : - interrupted Dst : ongoing - Name : completed Label : Mark as completed Src : - ongoing - started Dst : completed Using state machine descriptions with daptin expose couple of super useful apis to manage state based data. Enabling task_status state machine on todo entity will expose the following APIs POST /track/start/:stateMachineId { \"typeName\" : \"todo\" , \"referenceId\" : \"objectId\" } # Start tracking a particular object by id This returns a state machine id. POST /track/event/:typename/:objectStateMachineId/:eventName {} # Trigger event on current state This either moves the object state to next state, or fails on invalid event name. State machine Link A state machine is a description of \"states\" which the object can be in, and list of all valid transitions from one state to another. Let us begin with an example: The following JSON defines a state machine which has (a hypothetical state machine for tracking todos): Initial state: to_be_done List of valid states: to_be_done, delayed, started, ongoing, interrupted, completed List of valid transitions, giving name to each event { \"Name\" : \"task_status\" , \"Label\" : \"Task Status\" , \"InitialState\" : \"to_be_done\" , \"Events\" : [{ \"Name\" : \"start\" , \"Label\" : \"Start\" , \"Src\" : [ \"to_be_done\" , \"delayed\" ], \"Dst\" : \"started\" }, { \"Name\" : \"delayed\" , \"Label\" : \"Unable to pick up\" , \"Src\" : [ \"to_be_done\" ], \"Dst\" : \"delayed\" }, { \"Name\" : \"ongoing\" , \"Label\" : \"Record progress\" , \"Src\" : [ \"started\" , \"ongoing\" ], \"Dst\" : \"ongoing\" }, { \"Name\" : \"interrupted\" , \"Label\" : \"Interrupted\" , \"Src\" : [ \"started\" , \"ongoing\" ], \"Dst\" : \"interrupted\" }, { \"Name\" : \"resume\" , \"Label\" : \"Resume from interruption\" , \"Src\" : [ \"interrupted\" ], \"Dst\" : \"ongoing\" }, { \"Name\" : \"completed\" , \"Label\" : \"Mark as completed\" , \"Src\" : [ \"ongoing\" , \"started\" ], \"Dst\" : \"completed\" } ] } State machines can be uploaded to Daptin just like entities and actions. A JSON/YAML file with a StateMachineDescriptions top level key can contain an array of state machine descriptions. REST API Link Start tracking an object by state machine reference id Link Request POST /track/start/:stateMachineId {\"typeName\": <entityTypeName>, \"referenceId\": <ReferenceIdOfTheObject> } Response \"current_state\": <InitialStateOfTheStateMachine> \"<typename>_smd\": <ObjectStateInstanceReferenceId> \"is_state_of_<typename>\" = <ObjectInstanceId> \"permission\": <AuthPermission> Trigger an event by name in the state of an object Link POST /track/event/:typename/:ObjectStateInstanceReferenceId/:eventName Response \"current_state\": <NewStateAfterEvent> \"<typename>_smd\": <ObjectStateInstanceReferenceId> \"is_state_of_<typename>\" = <ObjectInstanceId> Enabling state tracking for entity Link Begin with marking an entity as trackable. To do this, go to the world tables page and edit the an entity Check the \"Is state tracking enabled\" checkbox This \"is_state_tracking_enabled\" options tells daptin to create the associated state table for the entity. Even though we have not yet specified which state machines are available for this entity. To make a state machine available for an entity, go to the \"SMD\" tab of this entity on the same page and add the state machine by searching it by name and adding it. It would not make a lot of sense if the above state machine was allowed for all type of entities.","title":"State tracking"},{"location":"state/machines/#state-tracking","text":"State of an object can help you tracing any sort of progress while making sure you maintain the consistence of the state. For eg, you might want to track the status of a \"blog post\" in terms of \"draft\"/\"edited\"/\"published\" which pre-defined endpoints defining the flow of states. Tracking the status of things is one of the most common operation in most business flows. Daptin has a native support for state tracking and allows a lot of convienent features.","title":"State tracking"},{"location":"state/machines/#defining-a-state-machine","text":"Define a state machine in YAML or JSON as follows: State machine description YAML StateMachineDescriptions : - Name : task_status Label : Task Status InitialState : to_be_done Events : - Name : start Label : Start Src : - to_be_done - delayed Dst : started - Name : delayed Label : Unable to pick up Src : - to_be_done Dst : delayed - Name : ongoing Label : Record progress Src : - started - ongoing Dst : ongoing - Name : interrupted Label : Interrupted Src : - started - ongoing Dst : interrupted - Name : resume Label : Resume from interruption Src : - interrupted Dst : ongoing - Name : completed Label : Mark as completed Src : - ongoing - started Dst : completed Using state machine descriptions with daptin expose couple of super useful apis to manage state based data. Enabling task_status state machine on todo entity will expose the following APIs POST /track/start/:stateMachineId { \"typeName\" : \"todo\" , \"referenceId\" : \"objectId\" } # Start tracking a particular object by id This returns a state machine id. POST /track/event/:typename/:objectStateMachineId/:eventName {} # Trigger event on current state This either moves the object state to next state, or fails on invalid event name.","title":"Defining a state machine"},{"location":"state/machines/#state-machine","text":"A state machine is a description of \"states\" which the object can be in, and list of all valid transitions from one state to another. Let us begin with an example: The following JSON defines a state machine which has (a hypothetical state machine for tracking todos): Initial state: to_be_done List of valid states: to_be_done, delayed, started, ongoing, interrupted, completed List of valid transitions, giving name to each event { \"Name\" : \"task_status\" , \"Label\" : \"Task Status\" , \"InitialState\" : \"to_be_done\" , \"Events\" : [{ \"Name\" : \"start\" , \"Label\" : \"Start\" , \"Src\" : [ \"to_be_done\" , \"delayed\" ], \"Dst\" : \"started\" }, { \"Name\" : \"delayed\" , \"Label\" : \"Unable to pick up\" , \"Src\" : [ \"to_be_done\" ], \"Dst\" : \"delayed\" }, { \"Name\" : \"ongoing\" , \"Label\" : \"Record progress\" , \"Src\" : [ \"started\" , \"ongoing\" ], \"Dst\" : \"ongoing\" }, { \"Name\" : \"interrupted\" , \"Label\" : \"Interrupted\" , \"Src\" : [ \"started\" , \"ongoing\" ], \"Dst\" : \"interrupted\" }, { \"Name\" : \"resume\" , \"Label\" : \"Resume from interruption\" , \"Src\" : [ \"interrupted\" ], \"Dst\" : \"ongoing\" }, { \"Name\" : \"completed\" , \"Label\" : \"Mark as completed\" , \"Src\" : [ \"ongoing\" , \"started\" ], \"Dst\" : \"completed\" } ] } State machines can be uploaded to Daptin just like entities and actions. A JSON/YAML file with a StateMachineDescriptions top level key can contain an array of state machine descriptions.","title":"State machine"},{"location":"state/machines/#rest-api","text":"","title":"REST API"},{"location":"state/machines/#start-tracking-an-object-by-state-machine-reference-id","text":"Request POST /track/start/:stateMachineId {\"typeName\": <entityTypeName>, \"referenceId\": <ReferenceIdOfTheObject> } Response \"current_state\": <InitialStateOfTheStateMachine> \"<typename>_smd\": <ObjectStateInstanceReferenceId> \"is_state_of_<typename>\" = <ObjectInstanceId> \"permission\": <AuthPermission>","title":"Start tracking an object by state machine reference id"},{"location":"state/machines/#trigger-an-event-by-name-in-the-state-of-an-object","text":"POST /track/event/:typename/:ObjectStateInstanceReferenceId/:eventName Response \"current_state\": <NewStateAfterEvent> \"<typename>_smd\": <ObjectStateInstanceReferenceId> \"is_state_of_<typename>\" = <ObjectInstanceId>","title":"Trigger an event by name in the state of an object"},{"location":"state/machines/#enabling-state-tracking-for-entity","text":"Begin with marking an entity as trackable. To do this, go to the world tables page and edit the an entity Check the \"Is state tracking enabled\" checkbox This \"is_state_tracking_enabled\" options tells daptin to create the associated state table for the entity. Even though we have not yet specified which state machines are available for this entity. To make a state machine available for an entity, go to the \"SMD\" tab of this entity on the same page and add the state machine by searching it by name and adding it. It would not make a lot of sense if the above state machine was allowed for all type of entities.","title":"Enabling state tracking for entity"},{"location":"streams/streams/","text":"Streams Link Streams are complimentary to actions . Think of streams as views in SQL. A stream is basically one entity + set of transformations and filters on the entity. Streams are read-only and exposed with similar semantics of that of entities. Daptin will expose JSONAPI for each stream just like it does for entities. Here is an example of a stream which exposes list of completed todos only { StreamName: \"transformed_user\", RootEntityName: \"todo\", Columns: []api2go.ColumnInfo{ // List of columns in this stream { Name: \"transformed_todo_title\", ColumnType: \"label\", }, { Name: \"completed_on\", ColumnType: \"datetime\", }, }, QueryParams: QueryParams{ \"Filter\": \"completed=true\", \"Select\": \"title,deadline\", }, Transformations: []Transformation{ { Operation: \"select\", Attributes: map[string]interface{}{ \"columns\": []string{\"title\", \"deadline\"}, }, }, { Operation: \"rename\", Attributes: map[string]interface{}{ \"oldName\": \"title\", \"newName\": \"transformed_todo_title\", }, }, { Operation: \"rename\", Attributes: map[string]interface{}{ \"oldName\": \"deadline\", \"newName\": \"completed_on\", }, }, }, } Daptin uses the library kniren/gota to systematically specific list of transformations which are applied to the original data stream.","title":"Data streams"},{"location":"streams/streams/#streams","text":"Streams are complimentary to actions . Think of streams as views in SQL. A stream is basically one entity + set of transformations and filters on the entity. Streams are read-only and exposed with similar semantics of that of entities. Daptin will expose JSONAPI for each stream just like it does for entities. Here is an example of a stream which exposes list of completed todos only { StreamName: \"transformed_user\", RootEntityName: \"todo\", Columns: []api2go.ColumnInfo{ // List of columns in this stream { Name: \"transformed_todo_title\", ColumnType: \"label\", }, { Name: \"completed_on\", ColumnType: \"datetime\", }, }, QueryParams: QueryParams{ \"Filter\": \"completed=true\", \"Select\": \"title,deadline\", }, Transformations: []Transformation{ { Operation: \"select\", Attributes: map[string]interface{}{ \"columns\": []string{\"title\", \"deadline\"}, }, }, { Operation: \"rename\", Attributes: map[string]interface{}{ \"oldName\": \"title\", \"newName\": \"transformed_todo_title\", }, }, { Operation: \"rename\", Attributes: map[string]interface{}{ \"oldName\": \"deadline\", \"newName\": \"completed_on\", }, }, }, } Daptin uses the library kniren/gota to systematically specific list of transformations which are applied to the original data stream.","title":"Streams"},{"location":"subsite/basic_auth/","text":"Protecting subsites from guests Link In addition to existing JWT based authentication, you can enable basic-auth over subsites since it is the quickest way to add authencation and doesn't require any action from end-users perspective apart from knowing the username and password. Also Basic auth is understood by a wide variety of browsers natively.","title":"Basic Authentication"},{"location":"subsite/basic_auth/#protecting-subsites-from-guests","text":"In addition to existing JWT based authentication, you can enable basic-auth over subsites since it is the quickest way to add authencation and doesn't require any action from end-users perspective apart from knowing the username and password. Also Basic auth is understood by a wide variety of browsers natively.","title":"Protecting subsites from guests"},{"location":"subsite/grapes/","text":"GrapesJS Link Todo: add documentation around live website editing","title":"Live editing a subsite"},{"location":"subsite/grapes/#grapesjs","text":"Todo: add documentation around live website editing","title":"GrapesJS"},{"location":"subsite/subsite/","text":"Sub site Link You can host multiple sites using daptin. A sub site is exposing a cloud storage folder statically under a sub-domain, domain or a path. Expose folders on cloud storage services as websites using your daptin instance. New subsite Select a cloud storage Choose a domain/sub-domain Choose a sub-path Restart is required to reflect changes. Creating a new sub-site Link Exposing a folder as a subsite Goto dashboard https://dashboard.domain.com/ Click \"Sub sites\" Click the green \"+\" icon Type in the hostname this should be exposed to this can be a domain or a sub-domain the domain should be pointing to the daptin instance Choose a name Path : select a sub directory name to expose this sub-site. Your sub-site will be accessible at domain.com/ Cloud store Id : choose an existing cloud store . Restart to enable serving the site. Daptin will sync the cloud store locally and start serving it under the domain/path.","title":"Creating a subsite"},{"location":"subsite/subsite/#sub-site","text":"You can host multiple sites using daptin. A sub site is exposing a cloud storage folder statically under a sub-domain, domain or a path. Expose folders on cloud storage services as websites using your daptin instance. New subsite Select a cloud storage Choose a domain/sub-domain Choose a sub-path Restart is required to reflect changes.","title":"Sub site"},{"location":"subsite/subsite/#creating-a-new-sub-site","text":"Exposing a folder as a subsite Goto dashboard https://dashboard.domain.com/ Click \"Sub sites\" Click the green \"+\" icon Type in the hostname this should be exposed to this can be a domain or a sub-domain the domain should be pointing to the daptin instance Choose a name Path : select a sub directory name to expose this sub-site. Your sub-site will be accessible at domain.com/ Cloud store Id : choose an existing cloud store . Restart to enable serving the site. Daptin will sync the cloud store locally and start serving it under the domain/path.","title":"Creating a new sub-site"}]}